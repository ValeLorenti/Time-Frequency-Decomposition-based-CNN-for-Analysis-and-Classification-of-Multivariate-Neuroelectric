{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCL_kEI5MaBQ"
      },
      "source": [
        "#**Drive mount**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPcE5wbH8VwQ",
        "outputId": "f5221b5a-e72a-4e18-ecd1-bd63ad3a93ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFUuzJuIAwe1"
      },
      "source": [
        "#**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEFsFcro8q0_"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms.functional as TF\n",
        "import sklearn.metrics\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torchvision.models as models\n",
        "from torchvision.models.resnet import resnet50\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.io import read_image\n",
        "from google.colab.patches import cv2_imshow\n",
        "#from PIL import ImageFile\n",
        "#ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPfeB-Cf9spV"
      },
      "source": [
        "#**Paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz6WyT7a7qBt"
      },
      "outputs": [],
      "source": [
        "sub_path = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/sub5'\n",
        "train_path = sub_path + '/train'\n",
        "test_path = sub_path + '/test'\n",
        "val_path = sub_path + '/val'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL-zaBVtJJA6"
      },
      "source": [
        "#**Preparo il trasformatore**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIsMIUkX_DQM"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])\n",
        "test_transforms = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])\n",
        "val_transforms = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8xD0fCUJQ0I"
      },
      "source": [
        "#**Carico il dataset in train, path e val trasformandolo direttamente con il trasformatore**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3pFN47gWYuK"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(root = train_path, transform = train_transforms)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root = test_path, transform = test_transforms)\n",
        "val_dataset = torchvision.datasets.ImageFolder(root = val_path, transform = val_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuErckneJXjs"
      },
      "source": [
        "#**Suddivido in dataloader per velocizzare l'allenamento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMUVMj48rA6Y"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 4, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 4, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 4, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-owV0WAaJkiG"
      },
      "source": [
        "#**Calcolo della mean e std per la normalizzazione valido sia per Grayscale che RGB, basta modificare il trasformatore**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lppxmCnuvfb"
      },
      "outputs": [],
      "source": [
        "def mean_and_std(loader):\n",
        "\n",
        "  channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "\n",
        "  for images, _ in loader:\n",
        "    channels_sum += torch.mean(images, dim=[0,2,3])\n",
        "    channels_squared_sum += torch.mean(images**2, dim=[0,2,3])\n",
        "    num_batches += 1\n",
        "\n",
        "  mean = channels_sum/num_batches\n",
        "  std = (channels_squared_sum/num_batches - mean**2)**0.5\n",
        "\n",
        "  return mean, std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMrsnWZyGl92"
      },
      "source": [
        "#**Trasformatori completi anche di normalizzazione**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2MrrgpQTww4"
      },
      "outputs": [],
      "source": [
        "mean, std = mean_and_std(train_loader)\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      #transforms.CenterCrop((224,192)),\n",
        "      #transforms.RandomHorizontalFlip(),\n",
        "      #transforms.RandomRotation(5),\n",
        "      #torchvision.transforms.RandomPerspective(distortion_scale=0.5, p=0.67, fill=0), #probability=0.67 per le indicazioni del medico\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
        "      \n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
        "      \n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBMda0ZoyE6k"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(root = train_path, transform = train_transforms)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root = test_path, transform = test_transforms)\n",
        "val_dataset = torchvision.datasets.ImageFolder(root = val_path, transform = val_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coJUvQ6MyI0R"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 4, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 4, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "io13dHqZXQav"
      },
      "outputs": [],
      "source": [
        "def show_transformed_images(dataset):\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size = 6, shuffle=True)\n",
        "    batch = next(iter(loader))\n",
        "    images, labels = batch\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 3)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    print(\"Labels:\", labels)\n",
        "\n",
        "show_transformed_images(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1, shuffle=True)\n",
        "batch = next(iter(loader))\n",
        "images, labels = batch\n",
        "images = torch.squeeze(images, dim=0)\n",
        "plt.imshow(np.transpose(images, (1,2,0)))\n",
        "plt.colorbar()\n",
        "plt.xlabel('sample')\n",
        "plt.ylabel('scale')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "f53KHs7tLyu-",
        "outputId": "4430535f-8fa6-4b78-fb37-3c6ddb3fec62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'scale')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA72ohaW8Mse"
      },
      "outputs": [],
      "source": [
        "def set_device():\n",
        "  if torch.cuda.is_available():\n",
        "    dev = \"cuda:0\"\n",
        "  else:\n",
        "    dev = \"cpu\"\n",
        "  return torch.device(dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FYUOo9TzdlZ"
      },
      "outputs": [],
      "source": [
        "plot_train_acc = []\n",
        "plot_val_acc = []\n",
        "plot_train_loss = []\n",
        "lrs = []\n",
        "\n",
        "def train_nn(model, train_loader, val_loader, optimizer, criterion, n_epochs):\n",
        "  device = set_device()\n",
        "  best_acc = 0\n",
        "  for epoch in range(n_epochs):\n",
        "    print(\"Epoch number %d\" %(epoch + 1))\n",
        "    model.train()\n",
        "    curr_loss = 0.0\n",
        "    curr_true = 0.0\n",
        "    total = 0\n",
        "    for data in train_loader:\n",
        "      images, labels = data\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      total += labels.size(0) #perche anche se il batch è da 32 l'ultimo potrebbe essere più piccolo\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1) #l'1 specifica il one dimension reduce\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      loss.backward()\n",
        "      \n",
        "      optimizer.step()\n",
        "\n",
        "      curr_loss += loss.item()\n",
        "      curr_true += (labels==predicted).sum().item()\n",
        "\n",
        "    epoch_loss = curr_loss/len(train_loader)\n",
        "    epoch_accuracy = (curr_true/total)*100\n",
        "    plot_train_acc.append(epoch_accuracy)\n",
        "    plot_train_loss.append(epoch_loss)\n",
        "    #scheduler.step()\n",
        "\n",
        "    print(\"   -- Training Dataset. Got %d out of %d images correctly (%.3f%%). Epoch Loss: %.3f\" %(curr_true, total, epoch_accuracy, epoch_loss))\n",
        "\n",
        "    val_acc = evaluate_model_val(model, val_loader)\n",
        "    plot_val_acc.append(val_acc)\n",
        "\n",
        "\n",
        "    if(val_acc >= best_acc):\n",
        "      best_acc = val_acc\n",
        "      save_checkpoint(model, epoch, optimizer, best_acc)\n",
        "      save_best_model(model)\n",
        "\n",
        "  print(\"\\n  -- Done!\")\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOJNSAbLOekH"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, epoch, optimizer, best_acc):\n",
        "  state = {\n",
        "      'epoch': epoch + 1,\n",
        "      'model': model.state_dict(),\n",
        "      'best accuracy': best_acc,\n",
        "      'optimizer': optimizer.state_dict(),\n",
        "      'comments': ' -- SUB 28 CON 10 -- '\n",
        "  }\n",
        "  torch.save(state, 'checkpoint.pth.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0ZmECbcmnQo"
      },
      "outputs": [],
      "source": [
        "def save_best_model(model):\n",
        "  torch.save(model, '/content/drive/MyDrive/Tirocinio/BestModels/BestModels_Wavelet/best_model.pth.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9eBg6Bnzd5U"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_val(model, val_loader):\n",
        "  model.eval()\n",
        "  true_predicted_on_epoch = 0\n",
        "  total = 0\n",
        "  device = set_device()\n",
        "\n",
        "  with torch.no_grad(): #reduce memory usage and speed up the evaluation (no backpropagation che non si fa sul test)\n",
        "    for data in val_loader:\n",
        "      images, labels = data\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      total += labels.size(0)\n",
        "\n",
        "      outputs = model(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "      true_predicted_on_epoch += (predicted==labels).sum().item()\n",
        "\n",
        "    epoch_accuracy = (true_predicted_on_epoch/total)*100\n",
        "\n",
        "    print(\"   -- Val Dataset. Got %d out of %d images correctly (%.3f%%)\" %(true_predicted_on_epoch, total, epoch_accuracy))\n",
        "\n",
        "  return epoch_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTgSpFQi09dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "c799fdb5cece46b1acc5a99cc49a6a8d",
            "bd97ebc357964538a2eb47c809909f05",
            "41366509067d4b4c8ad108735ce1f6aa",
            "6b624b1f0a9e498abb41131ed3078d98",
            "1e3aa6618aea4ced8c788eb63a319d58",
            "c525bd8bdb284129b7bbc4807efb1a56",
            "f5f722c148d44fa4ba7a5ecec25cd87a",
            "6d9f521f65754eddb489df920aeb8f27",
            "a5440fda81d4464e9458f4bed621e7ed",
            "2f5463aaed164dc3b1bd67713687256b",
            "497a3ff59bec43ba810cf62a21bebfcc"
          ]
        },
        "outputId": "4d523d1b-dfb2-4fa9-ccc6-60d853d0dce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c799fdb5cece46b1acc5a99cc49a6a8d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "num_classes = 2\n",
        "model.fc = nn.Linear(num_features, num_classes)\n",
        "device = set_device()\n",
        "model = model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=1e-5, dampening=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPMDCCNyxc07"
      },
      "outputs": [],
      "source": [
        "class OurNet(nn.Module):\n",
        "\n",
        "    def __init__(self, model, drop1, drop2):\n",
        "        super().__init__()\n",
        "\n",
        "        # ResNet50\n",
        "        self.network = model\n",
        "        \n",
        "        # Replace last layer\n",
        "        self.network._fc = nn.Sequential(nn.Conv2d(2048,512,(3, 3)),\n",
        "                                         nn.Linear(512, 128), \n",
        "                                         nn.SELU(),\n",
        "                                         nn.Dropout(drop1),\n",
        "                                         nn.BatchNorm2d(128),\n",
        "                                         nn.Linear(128, 32), \n",
        "                                         nn.SELU(),  \n",
        "                                         nn.Dropout(drop2),\n",
        "                                         nn.BatchNorm2d(32),\n",
        "                                         nn.Linear(32,num_classes))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.network(x)\n",
        "        return out\n",
        "\n",
        "model = OurNet(model, 0.6, 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEYBCHo75JO7"
      },
      "outputs": [],
      "source": [
        "train_nn(model, train_loader, val_loader, optimizer, loss_fn, 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IrKWJ_2ZOFg"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load('checkpoint.pth.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MholuvUKZZ8o",
        "outputId": "657ea0a2-182f-41d7-e838-ba11d4426d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171\n",
            "86.36363636363636\n",
            " -- SUB 5O CON 10 -- \n"
          ]
        }
      ],
      "source": [
        "print(checkpoint['epoch'])\n",
        "print(checkpoint['best accuracy'])\n",
        "print(checkpoint['comments'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XScKc95FoZAK"
      },
      "outputs": [],
      "source": [
        "best_model = torch.load('best_model.pth.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opB6x4rjYujj"
      },
      "outputs": [],
      "source": [
        "def showBadPredictedImages(predicteds, labels, imgs):\n",
        "  for i in range(len(labels)):\n",
        "    if predicteds[i] != labels[i]: #se la label predictada è diversa da quella effettiva\n",
        "      print(\"label: \", labels[i], \"predicted: \", predicteds[i])\n",
        "      img = imgs[i].permute(1, 2, 0) \n",
        "      plt.figure()\n",
        "      plt.imshow(img.numpy())\n",
        "      plt.show()\n",
        "      print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elFPurfekV8f"
      },
      "outputs": [],
      "source": [
        "all_pred = []\n",
        "all_true = []\n",
        "all_imgs = []\n",
        "\n",
        "def evaluate_model_test(best_model, test_loader):\n",
        "\n",
        "  best_model.eval()\n",
        "  true_predicted_on_epoch = 0\n",
        "  total = 0\n",
        "  device = set_device()\n",
        "  all_imgs = []\n",
        "  #all_true = []\n",
        "  \n",
        "  with torch.no_grad(): #reduce memory usage and speed up the evaluation\n",
        "    for data in test_loader:\n",
        "      images, labels = data\n",
        "\n",
        "      for img in images:\n",
        "        all_imgs.append(img) \n",
        "      for lab in labels:\n",
        "        all_true.append(float(lab))\n",
        "\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      total += labels.size(0)\n",
        "     \n",
        "      outputs = best_model(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      for pred in predicted:\n",
        "        all_pred.append(float(pred))\n",
        "\n",
        "\n",
        "      true_predicted_on_epoch += (predicted==labels).sum().item()\n",
        "    \n",
        "    epoch_accuracy = (true_predicted_on_epoch/total)*100\n",
        "  print(\"   -- Test Dataset. Got %d out of %d images correctly (%.3f%%)\" %(true_predicted_on_epoch, total, epoch_accuracy))\n",
        "  precisionEval = metrics.precision_score(all_true, all_pred, zero_division=1)\n",
        "  recallEval =  metrics.recall_score(all_true, all_pred, zero_division=1)\n",
        "  f1Score = metrics.f1_score(all_true, all_pred, zero_division=1)\n",
        "  print(\"   -- Test Dataset, recall: \", recallEval)\n",
        "  print(\"   -- Test Dataset, precision: \", precisionEval)\n",
        "  print(\"   -- Test Dataset, f1 score: \", f1Score)\n",
        "\n",
        "  return epoch_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOVq53QFi_Wq"
      },
      "outputs": [],
      "source": [
        "test_acc = evaluate_model_test(best_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W38VDDBwHvJN"
      },
      "source": [
        "##**Plots**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JQsxWNeLjNh"
      },
      "source": [
        "##**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFZ-v0TQLi8t"
      },
      "outputs": [],
      "source": [
        "def plotConfMatrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "def plotConfusions(true, predictions):\n",
        "    np.set_printoptions(precision=2)\n",
        "\n",
        "    class_names = [\"normal\", \"abnormal\"]\n",
        "    plotConfMatrix(true, predictions, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "    plotConfMatrix(true, predictions, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jlleujkHuIC"
      },
      "outputs": [],
      "source": [
        "plt.plot(plot_train_acc, label = \"Train Accuracy\")\n",
        "plt.plot(plot_val_acc, label = \"Val Accuracy\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(plot_train_loss, label = \"Loss\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(lrs, label = \"Learning Rate\")\n",
        "plt.xlabel('time steps')\n",
        "plt.ylabel('Lr')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(all_true)\n",
        "print(all_pred)\n",
        "\n",
        "plotConfusions(all_true, all_pred)\n",
        "\n",
        "print(\"Confusion matrixes plotted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wandb"
      ],
      "metadata": {
        "id": "WlTr3ZTPkr8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "14ksynCzkrhF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb385606-925e-458c-bffb-67f2aa163b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.4-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 37.7 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 69.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 69.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 52.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 52.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 72.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 67.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 76.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 69.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 76.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 68.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 72.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=56725345e3ea172df0ba4a0ba9596eaab0052c0bfe394fbf550e972c16a76837\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }\n",
        "\n",
        "metric = {\n",
        "    'name': 'val_acc',\n",
        "    'goal': 'maximize'   \n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "parameters_dict = {\n",
        "    \n",
        "    'optimizer': {\n",
        "        'values': ['sgd','rmsprop']\n",
        "        },\n",
        "\n",
        "    'drop1': {\n",
        "          'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "        },\n",
        "\n",
        "    'drop2': {\n",
        "          'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "        },\n",
        "\n",
        "    'learning_rate': {\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0.00001,\n",
        "        'max': 0.01\n",
        "    },\n",
        "    \n",
        "    'momentum': {\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0.9,\n",
        "        'max': 1.0\n",
        "    }  \n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project = \"TL_ResNet_Wavelet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbqRMEkEkw5H",
        "outputId": "a07858c7-7232-4c69-9710-be2478cf5c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 5gfiqykt\n",
            "Sweep URL: https://wandb.ai/valelore/TL_ResNet_Wavelet/sweeps/5gfiqykt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "all_pred = []\n",
        "all_true = []\n",
        "all_imgs = []\n",
        "\n",
        "def short_test(best_model):\n",
        "\n",
        "  best_model.eval()\n",
        "  true_predicted_on_epoch = 0\n",
        "  total = 0\n",
        "  device = set_device()\n",
        "  all_imgs = []\n",
        "  \n",
        "  with torch.no_grad(): #reduce memory usage and speed up the evaluation (no backpropagation che non si fa sul test)\n",
        "    for data in test_loader:\n",
        "      images, labels = data\n",
        "\n",
        "      for img in images:\n",
        "        all_imgs.append(img) #mi salvo in una lista le immagini per ogni batch alla fine le avrò tutte\n",
        "      for lab in labels:\n",
        "        all_true.append(float(lab)) #mi salvo in una lista le labels per ogni batch alla fine le avrò tutte\n",
        "\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      total += labels.size(0)\n",
        "     \n",
        "      outputs = best_model(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      for pred in predicted:\n",
        "        all_pred.append(float(pred)) #mi salvo tutte le prediction\n",
        "\n",
        "\n",
        "      true_predicted_on_epoch += (predicted==labels).sum().item()\n",
        "    \n",
        "    epoch_accuracy = (true_predicted_on_epoch/total)*100\n",
        "  print(\"   -- Test Dataset. Got %d out of %d images correctly (%.3f%%)\" %(true_predicted_on_epoch, total, epoch_accuracy))\n",
        "  precisionEval = metrics.precision_score(all_true, all_pred, zero_division=1)\n",
        "  recallEval =  metrics.recall_score(all_true, all_pred, zero_division=1)\n",
        "  f1Score = metrics.f1_score(all_true, all_pred, zero_division=1)\n",
        "  print(\"   -- Test Dataset, recall: \", recallEval)\n",
        "  print(\"   -- Test Dataset, precision: \", precisionEval)\n",
        "  print(\"   -- Test Dataset, f1 score: \", f1Score)\n",
        "  return epoch_accuracy"
      ],
      "metadata": {
        "id": "p7sUnsohk0NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "sweep_code = 0\n",
        "accuracies = {}\n",
        "\n",
        "def build_network(drop1, drop2):\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    num_features = model.fc.in_features\n",
        "    num_classes = 2\n",
        "    model.fc = nn.Linear(num_features, num_classes)\n",
        "    device = set_device()\n",
        "    model = model.to(device)\n",
        "    network = OurNet(model, drop1, drop2)\n",
        "\n",
        "    return network\n",
        "\n",
        "def build_optimizer(network, optimizer, learning_rate, mom):\n",
        "    if optimizer == \"rmsprop\":\n",
        "        optimizer = optim.RMSprop(network.parameters(),\n",
        "                              lr=learning_rate)\n",
        "    elif optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(network.parameters(),\n",
        "                               lr=learning_rate, momentum = mom)\n",
        "    return optimizer\n",
        "\n",
        "def train_epoch(model, train_loader, val_loader, optimizer, best_loss = 10000):\n",
        "  model.train()\n",
        "  curr_loss = 0.0\n",
        "  curr_true = 0.0\n",
        "  total = 0\n",
        "  for data in train_loader:\n",
        "    images, labels = data\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    total += labels.size(0) #perche anche se il batch è da 32 l'ultimo potrebbe essere più piccolo\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1) #l'1 specifica il one dimension reduce\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "    curr_loss += loss.item()\n",
        "    curr_true += (labels==predicted).sum().item()\n",
        "\n",
        "  return curr_loss, curr_true, total\n",
        "\n",
        "def train(config=None):\n",
        "\n",
        "    with wandb.init(config=config):\n",
        "\n",
        "        config = wandb.config\n",
        "\n",
        "        best_acc = 0\n",
        "        network = build_network(config.drop1, config.drop2)\n",
        "        optimizer = build_optimizer(network, config.optimizer, config.learning_rate, config.momentum)\n",
        "        best_loss = 10000\n",
        "        n_epochs = 200\n",
        "        for epoch in range(n_epochs):\n",
        "          print(\"Epoch number %d\" %(epoch + 1))\n",
        "          curr_loss, curr_true, total = train_epoch(network, train_loader, val_loader, optimizer, best_loss)\n",
        "          epoch_loss = curr_loss/len(train_loader)\n",
        "          epoch_accuracy = (curr_true/total)*100\n",
        "\n",
        "          print(\"   -- Training Dataset. Got %d out of %d images correctly (%.3f%%). Epoch Loss: %.3f\" %(curr_true, total, epoch_accuracy, epoch_loss))\n",
        "\n",
        "          val_acc = evaluate_model_val(network, val_loader)\n",
        "\n",
        "\n",
        "          if(val_acc >= best_acc):\n",
        "            best_acc = val_acc\n",
        "            save_checkpoint(network, epoch, optimizer, best_acc)\n",
        "            save_best_model(network)\n",
        "\n",
        "          wandb.log({\n",
        "              'Train acc': epoch_accuracy,\n",
        "              'Train loss': epoch_loss,\n",
        "              'Val acc': val_acc\n",
        "            })\n",
        "\n",
        "        print(\"\\n  -- Done!\")\n",
        "        CURR_DIR = '/content/drive/MyDrive/Tirocinio/BestModels/BestModels_Wavelet'\n",
        "        global sweep_code\n",
        "        os.mkdir(CURR_DIR + \"/\" + str(sweep_code))\n",
        "        os.replace(CURR_DIR + \"/best_model.pth.tar\", CURR_DIR + \"/\" + str(sweep_code) + \"/best_model.pth.tar\")\n",
        "        \n",
        "        network = torch.load(CURR_DIR + \"/\" + str(sweep_code) + \"/best_model.pth.tar\")\n",
        "        acc = short_test(network)\n",
        "        wandb.log({\"test_accuracy\": acc})\n",
        "        sweep_code = sweep_code + 1\n"
      ],
      "metadata": {
        "id": "QOUT9eaTk5A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, count = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YdUIyE5Vk-FS",
        "outputId": "2a202e17-4bfc-418b-9f8b-51e857884c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7wj5vmf4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop1: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop2: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.007863365817815658\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.917998625007702\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvalelore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221016_162228-7wj5vmf4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/valelore/TL_ResNet_Wavelet/runs/7wj5vmf4\" target=\"_blank\">stilted-sweep-1</a></strong> to <a href=\"https://wandb.ai/valelore/TL_ResNet_Wavelet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/valelore/TL_ResNet_Wavelet/sweeps/5gfiqykt\" target=\"_blank\">https://wandb.ai/valelore/TL_ResNet_Wavelet/sweeps/5gfiqykt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch number 1\n",
            "   -- Training Dataset. Got 87 out of 158 images correctly (55.063%). Epoch Loss: 1.631\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 2\n",
            "   -- Training Dataset. Got 67 out of 158 images correctly (42.405%). Epoch Loss: 1.723\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 3\n",
            "   -- Training Dataset. Got 82 out of 158 images correctly (51.899%). Epoch Loss: 0.953\n",
            "   -- Val Dataset. Got 8 out of 22 images correctly (36.364%)\n",
            "Epoch number 4\n",
            "   -- Training Dataset. Got 90 out of 158 images correctly (56.962%). Epoch Loss: 1.353\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 5\n",
            "   -- Training Dataset. Got 79 out of 158 images correctly (50.000%). Epoch Loss: 1.211\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 6\n",
            "   -- Training Dataset. Got 76 out of 158 images correctly (48.101%). Epoch Loss: 1.042\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 7\n",
            "   -- Training Dataset. Got 70 out of 158 images correctly (44.304%). Epoch Loss: 0.811\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 8\n",
            "   -- Training Dataset. Got 67 out of 158 images correctly (42.405%). Epoch Loss: 0.818\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 9\n",
            "   -- Training Dataset. Got 83 out of 158 images correctly (52.532%). Epoch Loss: 0.723\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 10\n",
            "   -- Training Dataset. Got 71 out of 158 images correctly (44.937%). Epoch Loss: 0.766\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 11\n",
            "   -- Training Dataset. Got 87 out of 158 images correctly (55.063%). Epoch Loss: 0.745\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 12\n",
            "   -- Training Dataset. Got 88 out of 158 images correctly (55.696%). Epoch Loss: 0.756\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 13\n",
            "   -- Training Dataset. Got 73 out of 158 images correctly (46.203%). Epoch Loss: 0.755\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 14\n",
            "   -- Training Dataset. Got 91 out of 158 images correctly (57.595%). Epoch Loss: 0.704\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 15\n",
            "   -- Training Dataset. Got 79 out of 158 images correctly (50.000%). Epoch Loss: 0.728\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 16\n",
            "   -- Training Dataset. Got 82 out of 158 images correctly (51.899%). Epoch Loss: 0.728\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 17\n",
            "   -- Training Dataset. Got 75 out of 158 images correctly (47.468%). Epoch Loss: 0.727\n",
            "   -- Val Dataset. Got 9 out of 22 images correctly (40.909%)\n",
            "Epoch number 18\n",
            "   -- Training Dataset. Got 75 out of 158 images correctly (47.468%). Epoch Loss: 0.725\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 19\n",
            "   -- Training Dataset. Got 77 out of 158 images correctly (48.734%). Epoch Loss: 0.728\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 20\n",
            "   -- Training Dataset. Got 76 out of 158 images correctly (48.101%). Epoch Loss: 0.817\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 21\n",
            "   -- Training Dataset. Got 78 out of 158 images correctly (49.367%). Epoch Loss: 0.711\n",
            "   -- Val Dataset. Got 9 out of 22 images correctly (40.909%)\n",
            "Epoch number 22\n",
            "   -- Training Dataset. Got 73 out of 158 images correctly (46.203%). Epoch Loss: 0.712\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 23\n",
            "   -- Training Dataset. Got 69 out of 158 images correctly (43.671%). Epoch Loss: 0.729\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 24\n",
            "   -- Training Dataset. Got 78 out of 158 images correctly (49.367%). Epoch Loss: 0.742\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 25\n",
            "   -- Training Dataset. Got 80 out of 158 images correctly (50.633%). Epoch Loss: 0.718\n",
            "   -- Val Dataset. Got 9 out of 22 images correctly (40.909%)\n",
            "Epoch number 26\n",
            "   -- Training Dataset. Got 83 out of 158 images correctly (52.532%). Epoch Loss: 0.732\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 27\n",
            "   -- Training Dataset. Got 90 out of 158 images correctly (56.962%). Epoch Loss: 0.709\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 28\n",
            "   -- Training Dataset. Got 83 out of 158 images correctly (52.532%). Epoch Loss: 0.720\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 29\n",
            "   -- Training Dataset. Got 95 out of 158 images correctly (60.127%). Epoch Loss: 0.669\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 30\n",
            "   -- Training Dataset. Got 90 out of 158 images correctly (56.962%). Epoch Loss: 0.726\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 31\n",
            "   -- Training Dataset. Got 87 out of 158 images correctly (55.063%). Epoch Loss: 0.712\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 32\n",
            "   -- Training Dataset. Got 78 out of 158 images correctly (49.367%). Epoch Loss: 0.701\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 33\n",
            "   -- Training Dataset. Got 97 out of 158 images correctly (61.392%). Epoch Loss: 0.690\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 34\n",
            "   -- Training Dataset. Got 90 out of 158 images correctly (56.962%). Epoch Loss: 0.688\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 35\n",
            "   -- Training Dataset. Got 89 out of 158 images correctly (56.329%). Epoch Loss: 0.727\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 36\n",
            "   -- Training Dataset. Got 77 out of 158 images correctly (48.734%). Epoch Loss: 0.791\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 37\n",
            "   -- Training Dataset. Got 81 out of 158 images correctly (51.266%). Epoch Loss: 0.697\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 38\n",
            "   -- Training Dataset. Got 82 out of 158 images correctly (51.899%). Epoch Loss: 0.704\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 39\n",
            "   -- Training Dataset. Got 96 out of 158 images correctly (60.759%). Epoch Loss: 0.681\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 40\n",
            "   -- Training Dataset. Got 94 out of 158 images correctly (59.494%). Epoch Loss: 0.648\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 41\n",
            "   -- Training Dataset. Got 108 out of 158 images correctly (68.354%). Epoch Loss: 0.629\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 42\n",
            "   -- Training Dataset. Got 87 out of 158 images correctly (55.063%). Epoch Loss: 0.715\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 43\n",
            "   -- Training Dataset. Got 95 out of 158 images correctly (60.127%). Epoch Loss: 0.675\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 44\n",
            "   -- Training Dataset. Got 94 out of 158 images correctly (59.494%). Epoch Loss: 0.721\n",
            "   -- Val Dataset. Got 16 out of 22 images correctly (72.727%)\n",
            "Epoch number 45\n",
            "   -- Training Dataset. Got 99 out of 158 images correctly (62.658%). Epoch Loss: 0.655\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 46\n",
            "   -- Training Dataset. Got 109 out of 158 images correctly (68.987%). Epoch Loss: 0.632\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 47\n",
            "   -- Training Dataset. Got 99 out of 158 images correctly (62.658%). Epoch Loss: 0.641\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 48\n",
            "   -- Training Dataset. Got 112 out of 158 images correctly (70.886%). Epoch Loss: 0.576\n",
            "   -- Val Dataset. Got 16 out of 22 images correctly (72.727%)\n",
            "Epoch number 49\n",
            "   -- Training Dataset. Got 92 out of 158 images correctly (58.228%). Epoch Loss: 0.723\n",
            "   -- Val Dataset. Got 16 out of 22 images correctly (72.727%)\n",
            "Epoch number 50\n",
            "   -- Training Dataset. Got 92 out of 158 images correctly (58.228%). Epoch Loss: 0.649\n",
            "   -- Val Dataset. Got 16 out of 22 images correctly (72.727%)\n",
            "Epoch number 51\n",
            "   -- Training Dataset. Got 104 out of 158 images correctly (65.823%). Epoch Loss: 0.642\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 52\n",
            "   -- Training Dataset. Got 111 out of 158 images correctly (70.253%). Epoch Loss: 0.611\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 53\n",
            "   -- Training Dataset. Got 105 out of 158 images correctly (66.456%). Epoch Loss: 0.607\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 54\n",
            "   -- Training Dataset. Got 109 out of 158 images correctly (68.987%). Epoch Loss: 0.585\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 55\n",
            "   -- Training Dataset. Got 117 out of 158 images correctly (74.051%). Epoch Loss: 0.542\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 56\n",
            "   -- Training Dataset. Got 108 out of 158 images correctly (68.354%). Epoch Loss: 0.605\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 57\n",
            "   -- Training Dataset. Got 116 out of 158 images correctly (73.418%). Epoch Loss: 0.518\n",
            "   -- Val Dataset. Got 16 out of 22 images correctly (72.727%)\n",
            "Epoch number 58\n",
            "   -- Training Dataset. Got 120 out of 158 images correctly (75.949%). Epoch Loss: 0.516\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 59\n",
            "   -- Training Dataset. Got 112 out of 158 images correctly (70.886%). Epoch Loss: 0.549\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 60\n",
            "   -- Training Dataset. Got 127 out of 158 images correctly (80.380%). Epoch Loss: 0.397\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 61\n",
            "   -- Training Dataset. Got 133 out of 158 images correctly (84.177%). Epoch Loss: 0.396\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 62\n",
            "   -- Training Dataset. Got 131 out of 158 images correctly (82.911%). Epoch Loss: 0.467\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 63\n",
            "   -- Training Dataset. Got 122 out of 158 images correctly (77.215%). Epoch Loss: 0.563\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 64\n",
            "   -- Training Dataset. Got 133 out of 158 images correctly (84.177%). Epoch Loss: 0.418\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 65\n",
            "   -- Training Dataset. Got 137 out of 158 images correctly (86.709%). Epoch Loss: 0.336\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 66\n",
            "   -- Training Dataset. Got 127 out of 158 images correctly (80.380%). Epoch Loss: 0.413\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 67\n",
            "   -- Training Dataset. Got 145 out of 158 images correctly (91.772%). Epoch Loss: 0.237\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 68\n",
            "   -- Training Dataset. Got 137 out of 158 images correctly (86.709%). Epoch Loss: 0.332\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 69\n",
            "   -- Training Dataset. Got 130 out of 158 images correctly (82.278%). Epoch Loss: 0.371\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 70\n",
            "   -- Training Dataset. Got 131 out of 158 images correctly (82.911%). Epoch Loss: 0.384\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 71\n",
            "   -- Training Dataset. Got 138 out of 158 images correctly (87.342%). Epoch Loss: 0.315\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 72\n",
            "   -- Training Dataset. Got 150 out of 158 images correctly (94.937%). Epoch Loss: 0.184\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 73\n",
            "   -- Training Dataset. Got 140 out of 158 images correctly (88.608%). Epoch Loss: 0.304\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 74\n",
            "   -- Training Dataset. Got 136 out of 158 images correctly (86.076%). Epoch Loss: 0.319\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 75\n",
            "   -- Training Dataset. Got 150 out of 158 images correctly (94.937%). Epoch Loss: 0.164\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 76\n",
            "   -- Training Dataset. Got 152 out of 158 images correctly (96.203%). Epoch Loss: 0.126\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 77\n",
            "   -- Training Dataset. Got 151 out of 158 images correctly (95.570%). Epoch Loss: 0.121\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 78\n",
            "   -- Training Dataset. Got 149 out of 158 images correctly (94.304%). Epoch Loss: 0.146\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 79\n",
            "   -- Training Dataset. Got 152 out of 158 images correctly (96.203%). Epoch Loss: 0.152\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 80\n",
            "   -- Training Dataset. Got 149 out of 158 images correctly (94.304%). Epoch Loss: 0.152\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 81\n",
            "   -- Training Dataset. Got 155 out of 158 images correctly (98.101%). Epoch Loss: 0.049\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 82\n",
            "   -- Training Dataset. Got 155 out of 158 images correctly (98.101%). Epoch Loss: 0.109\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 83\n",
            "   -- Training Dataset. Got 154 out of 158 images correctly (97.468%). Epoch Loss: 0.084\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 84\n",
            "   -- Training Dataset. Got 153 out of 158 images correctly (96.835%). Epoch Loss: 0.110\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 85\n",
            "   -- Training Dataset. Got 154 out of 158 images correctly (97.468%). Epoch Loss: 0.074\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 86\n",
            "   -- Training Dataset. Got 154 out of 158 images correctly (97.468%). Epoch Loss: 0.067\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 87\n",
            "   -- Training Dataset. Got 141 out of 158 images correctly (89.241%). Epoch Loss: 0.279\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 88\n",
            "   -- Training Dataset. Got 151 out of 158 images correctly (95.570%). Epoch Loss: 0.109\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 89\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.024\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 90\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.016\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 91\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.016\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 92\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.008\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 93\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.009\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 94\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.010\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 95\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.008\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 96\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.004\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 97\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.003\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 98\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.003\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 99\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 100\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 101\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 102\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 103\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 104\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 105\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.004\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 106\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.005\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 107\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 108\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.004\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 109\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 110\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 111\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 112\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 113\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 114\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 115\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 116\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 117\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 118\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 119\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 120\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 121\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 122\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 123\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 124\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 125\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 126\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 127\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 128\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 129\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 130\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 131\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 132\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 133\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 134\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 135\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 136\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 137\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 138\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 139\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 140\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 141\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 10 out of 22 images correctly (45.455%)\n",
            "Epoch number 142\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 143\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 144\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 145\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 146\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 147\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 148\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 149\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 150\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 151\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 152\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 153\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 154\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 155\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 156\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 157\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 158\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 159\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 160\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 161\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 162\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 163\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 164\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 165\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 166\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 167\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 168\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 169\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 170\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 171\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 172\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 173\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 174\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 175\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 176\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 177\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 178\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 179\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 180\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 181\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 182\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 183\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 184\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 185\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 186\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 187\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 188\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 189\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 190\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 191\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 192\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 193\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 194\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 195\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 196\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 197\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 198\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 199\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 200\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "\n",
            "  -- Done!\n",
            "   -- Test Dataset. Got 29 out of 44 images correctly (65.909%)\n",
            "   -- Test Dataset, recall:  0.7272727272727273\n",
            "   -- Test Dataset, precision:  0.64\n",
            "   -- Test Dataset, f1 score:  0.6808510638297872\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train acc</td><td>▁▂▃▂▁▂▂▂▃▄▄▄▆▆▇▇█▇██████████████████████</td></tr><tr><td>Train loss</td><td>█▅▄▄▄▄▄▄▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val acc</td><td>▁▁▆▁▁▁▁▅▃█▆█▅▁▆▆▆▃▆▅▆▆▃▃▁▆█▅█▅▅▅▃▅▅▅▆██▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train acc</td><td>100.0</td></tr><tr><td>Train loss</td><td>9e-05</td></tr><tr><td>Val acc</td><td>50.0</td></tr><tr><td>test_accuracy</td><td>65.90909</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">stilted-sweep-1</strong>: <a href=\"https://wandb.ai/valelore/TL_ResNet_Wavelet/runs/7wj5vmf4\" target=\"_blank\">https://wandb.ai/valelore/TL_ResNet_Wavelet/runs/7wj5vmf4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221016_162228-7wj5vmf4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2bz6s33n with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop1: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop2: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003861620384614781\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9495211225977824\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221016_164954-2bz6s33n</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/valelore/TL_ResNet_Wavelet/runs/2bz6s33n\" target=\"_blank\">smart-sweep-2</a></strong> to <a href=\"https://wandb.ai/valelore/TL_ResNet_Wavelet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/valelore/TL_ResNet_Wavelet/sweeps/5gfiqykt\" target=\"_blank\">https://wandb.ai/valelore/TL_ResNet_Wavelet/sweeps/5gfiqykt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch number 1\n",
            "   -- Training Dataset. Got 94 out of 158 images correctly (59.494%). Epoch Loss: 1.546\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 2\n",
            "   -- Training Dataset. Got 88 out of 158 images correctly (55.696%). Epoch Loss: 0.818\n",
            "   -- Val Dataset. Got 17 out of 22 images correctly (77.273%)\n",
            "Epoch number 3\n",
            "   -- Training Dataset. Got 103 out of 158 images correctly (65.190%). Epoch Loss: 0.756\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 4\n",
            "   -- Training Dataset. Got 112 out of 158 images correctly (70.886%). Epoch Loss: 0.679\n",
            "   -- Val Dataset. Got 16 out of 22 images correctly (72.727%)\n",
            "Epoch number 5\n",
            "   -- Training Dataset. Got 110 out of 158 images correctly (69.620%). Epoch Loss: 0.661\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 6\n",
            "   -- Training Dataset. Got 121 out of 158 images correctly (76.582%). Epoch Loss: 0.520\n",
            "   -- Val Dataset. Got 17 out of 22 images correctly (77.273%)\n",
            "Epoch number 7\n",
            "   -- Training Dataset. Got 123 out of 158 images correctly (77.848%). Epoch Loss: 0.506\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 8\n",
            "   -- Training Dataset. Got 128 out of 158 images correctly (81.013%). Epoch Loss: 0.473\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 9\n",
            "   -- Training Dataset. Got 126 out of 158 images correctly (79.747%). Epoch Loss: 0.512\n",
            "   -- Val Dataset. Got 17 out of 22 images correctly (77.273%)\n",
            "Epoch number 10\n",
            "   -- Training Dataset. Got 147 out of 158 images correctly (93.038%). Epoch Loss: 0.290\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 11\n",
            "   -- Training Dataset. Got 134 out of 158 images correctly (84.810%). Epoch Loss: 0.365\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 12\n",
            "   -- Training Dataset. Got 129 out of 158 images correctly (81.646%). Epoch Loss: 0.449\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 13\n",
            "   -- Training Dataset. Got 140 out of 158 images correctly (88.608%). Epoch Loss: 0.267\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 14\n",
            "   -- Training Dataset. Got 146 out of 158 images correctly (92.405%). Epoch Loss: 0.273\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 15\n",
            "   -- Training Dataset. Got 136 out of 158 images correctly (86.076%). Epoch Loss: 0.361\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 16\n",
            "   -- Training Dataset. Got 139 out of 158 images correctly (87.975%). Epoch Loss: 0.331\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 17\n",
            "   -- Training Dataset. Got 144 out of 158 images correctly (91.139%). Epoch Loss: 0.197\n",
            "   -- Val Dataset. Got 16 out of 22 images correctly (72.727%)\n",
            "Epoch number 18\n",
            "   -- Training Dataset. Got 122 out of 158 images correctly (77.215%). Epoch Loss: 0.694\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 19\n",
            "   -- Training Dataset. Got 138 out of 158 images correctly (87.342%). Epoch Loss: 0.288\n",
            "   -- Val Dataset. Got 17 out of 22 images correctly (77.273%)\n",
            "Epoch number 20\n",
            "   -- Training Dataset. Got 147 out of 158 images correctly (93.038%). Epoch Loss: 0.158\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 21\n",
            "   -- Training Dataset. Got 141 out of 158 images correctly (89.241%). Epoch Loss: 0.308\n",
            "   -- Val Dataset. Got 16 out of 22 images correctly (72.727%)\n",
            "Epoch number 22\n",
            "   -- Training Dataset. Got 143 out of 158 images correctly (90.506%). Epoch Loss: 0.235\n",
            "   -- Val Dataset. Got 17 out of 22 images correctly (77.273%)\n",
            "Epoch number 23\n",
            "   -- Training Dataset. Got 152 out of 158 images correctly (96.203%). Epoch Loss: 0.127\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 24\n",
            "   -- Training Dataset. Got 151 out of 158 images correctly (95.570%). Epoch Loss: 0.088\n",
            "   -- Val Dataset. Got 21 out of 22 images correctly (95.455%)\n",
            "Epoch number 25\n",
            "   -- Training Dataset. Got 146 out of 158 images correctly (92.405%). Epoch Loss: 0.167\n",
            "   -- Val Dataset. Got 21 out of 22 images correctly (95.455%)\n",
            "Epoch number 26\n",
            "   -- Training Dataset. Got 149 out of 158 images correctly (94.304%). Epoch Loss: 0.117\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 27\n",
            "   -- Training Dataset. Got 152 out of 158 images correctly (96.203%). Epoch Loss: 0.104\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 28\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.032\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 29\n",
            "   -- Training Dataset. Got 152 out of 158 images correctly (96.203%). Epoch Loss: 0.109\n",
            "   -- Val Dataset. Got 17 out of 22 images correctly (77.273%)\n",
            "Epoch number 30\n",
            "   -- Training Dataset. Got 157 out of 158 images correctly (99.367%). Epoch Loss: 0.032\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 31\n",
            "   -- Training Dataset. Got 156 out of 158 images correctly (98.734%). Epoch Loss: 0.025\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 32\n",
            "   -- Training Dataset. Got 157 out of 158 images correctly (99.367%). Epoch Loss: 0.016\n",
            "   -- Val Dataset. Got 17 out of 22 images correctly (77.273%)\n",
            "Epoch number 33\n",
            "   -- Training Dataset. Got 156 out of 158 images correctly (98.734%). Epoch Loss: 0.039\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 34\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.015\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 35\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.008\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 36\n",
            "   -- Training Dataset. Got 157 out of 158 images correctly (99.367%). Epoch Loss: 0.019\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 37\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.004\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 38\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.004\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 39\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.003\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 40\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 41\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 42\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 43\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.002\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 44\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 45\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 46\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 47\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 48\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 49\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 50\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 51\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 52\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 53\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 54\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 55\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.001\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 56\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 57\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 58\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 59\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 60\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 61\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 62\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 63\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 64\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 65\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 66\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 67\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 68\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 69\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 70\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 71\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 72\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 73\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 74\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 75\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 76\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 77\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 78\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 79\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 80\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 81\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 82\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 83\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 84\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 85\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 86\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 87\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 88\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 89\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 90\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 91\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 92\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 93\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 94\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 95\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 96\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 97\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 98\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 99\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 100\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 101\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 102\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 103\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 104\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 105\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 106\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 107\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 108\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 109\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 110\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 111\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 112\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 113\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 114\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 115\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 116\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 117\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 118\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 119\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 120\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 121\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 122\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 123\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 124\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 125\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 126\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 127\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 128\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 129\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 130\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 131\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 132\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 133\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 134\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 135\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 136\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 137\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 138\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 139\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 140\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 141\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 142\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 143\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 144\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 145\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 146\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 147\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 148\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 149\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 150\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 151\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 152\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 153\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 154\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 155\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 156\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 157\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 158\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 159\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 160\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 161\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 162\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 163\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 164\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 165\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 166\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 167\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 168\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 169\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 170\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 171\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 172\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 173\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 174\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 175\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 176\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 177\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 178\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 179\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 180\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 181\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 18 out of 22 images correctly (81.818%)\n",
            "Epoch number 182\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 183\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 184\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 185\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 186\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 187\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 188\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 189\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 190\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 191\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 192\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 193\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 194\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 195\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 196\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 197\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 19 out of 22 images correctly (86.364%)\n",
            "Epoch number 198\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 199\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 200\n",
            "   -- Training Dataset. Got 158 out of 158 images correctly (100.000%). Epoch Loss: 0.000\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "\n",
            "  -- Done!\n",
            "   -- Test Dataset. Got 34 out of 44 images correctly (77.273%)\n",
            "   -- Test Dataset, recall:  0.8181818181818182\n",
            "   -- Test Dataset, precision:  0.6792452830188679\n",
            "   -- Test Dataset, f1 score:  0.7422680412371134\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train acc</td><td>▁▄▅▆▇▇██████████████████████████████████</td></tr><tr><td>Train loss</td><td>█▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val acc</td><td>▁▁█▆▁█▁▃▃▃▃▃▃██▆▆▆▆▃█▆█▆██▆███▆███████▆█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train acc</td><td>100.0</td></tr><tr><td>Train loss</td><td>7e-05</td></tr><tr><td>Val acc</td><td>90.90909</td></tr><tr><td>test_accuracy</td><td>77.27273</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">smart-sweep-2</strong>: <a href=\"https://wandb.ai/valelore/TL_ResNet_Wavelet/runs/2bz6s33n\" target=\"_blank\">https://wandb.ai/valelore/TL_ResNet_Wavelet/runs/2bz6s33n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221016_164954-2bz6s33n/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 94s5jxf8 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop1: 0.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop2: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006784611182909463\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.900569178085108\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221016_171534-94s5jxf8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/valelore/TL_ResNet_Wavelet/runs/94s5jxf8\" target=\"_blank\">sweepy-sweep-3</a></strong> to <a href=\"https://wandb.ai/valelore/TL_ResNet_Wavelet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/valelore/TL_ResNet_Wavelet/sweeps/5gfiqykt\" target=\"_blank\">https://wandb.ai/valelore/TL_ResNet_Wavelet/sweeps/5gfiqykt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch number 1\n",
            "   -- Training Dataset. Got 78 out of 158 images correctly (49.367%). Epoch Loss: 2.313\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 2\n",
            "   -- Training Dataset. Got 77 out of 158 images correctly (48.734%). Epoch Loss: 0.745\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 3\n",
            "   -- Training Dataset. Got 84 out of 158 images correctly (53.165%). Epoch Loss: 0.716\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 4\n",
            "   -- Training Dataset. Got 69 out of 158 images correctly (43.671%). Epoch Loss: 0.714\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 5\n",
            "   -- Training Dataset. Got 89 out of 158 images correctly (56.329%). Epoch Loss: 0.694\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 6\n",
            "   -- Training Dataset. Got 75 out of 158 images correctly (47.468%). Epoch Loss: 0.705\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 7\n",
            "   -- Training Dataset. Got 83 out of 158 images correctly (52.532%). Epoch Loss: 0.699\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 8\n",
            "   -- Training Dataset. Got 77 out of 158 images correctly (48.734%). Epoch Loss: 0.703\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 9\n",
            "   -- Training Dataset. Got 77 out of 158 images correctly (48.734%). Epoch Loss: 0.698\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 10\n",
            "   -- Training Dataset. Got 87 out of 158 images correctly (55.063%). Epoch Loss: 0.699\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 11\n",
            "   -- Training Dataset. Got 72 out of 158 images correctly (45.570%). Epoch Loss: 0.699\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 12\n",
            "   -- Training Dataset. Got 79 out of 158 images correctly (50.000%). Epoch Loss: 0.697\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 13\n",
            "   -- Training Dataset. Got 71 out of 158 images correctly (44.937%). Epoch Loss: 0.697\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 14\n",
            "   -- Training Dataset. Got 81 out of 158 images correctly (51.266%). Epoch Loss: 0.789\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 15\n",
            "   -- Training Dataset. Got 72 out of 158 images correctly (45.570%). Epoch Loss: 0.712\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 16\n",
            "   -- Training Dataset. Got 78 out of 158 images correctly (49.367%). Epoch Loss: 0.713\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 17\n",
            "   -- Training Dataset. Got 92 out of 158 images correctly (58.228%). Epoch Loss: 0.669\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 18\n",
            "   -- Training Dataset. Got 70 out of 158 images correctly (44.304%). Epoch Loss: 0.726\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 19\n",
            "   -- Training Dataset. Got 91 out of 158 images correctly (57.595%). Epoch Loss: 0.699\n",
            "   -- Val Dataset. Got 20 out of 22 images correctly (90.909%)\n",
            "Epoch number 20\n",
            "   -- Training Dataset. Got 77 out of 158 images correctly (48.734%). Epoch Loss: 0.702\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 21\n",
            "   -- Training Dataset. Got 76 out of 158 images correctly (48.101%). Epoch Loss: 0.706\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 22\n",
            "   -- Training Dataset. Got 77 out of 158 images correctly (48.734%). Epoch Loss: 0.701\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 23\n",
            "   -- Training Dataset. Got 76 out of 158 images correctly (48.101%). Epoch Loss: 0.719\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 24\n",
            "   -- Training Dataset. Got 72 out of 158 images correctly (45.570%). Epoch Loss: 0.715\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 25\n",
            "   -- Training Dataset. Got 80 out of 158 images correctly (50.633%). Epoch Loss: 0.734\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 26\n",
            "   -- Training Dataset. Got 85 out of 158 images correctly (53.797%). Epoch Loss: 0.702\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 27\n",
            "   -- Training Dataset. Got 89 out of 158 images correctly (56.329%). Epoch Loss: 0.677\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 28\n",
            "   -- Training Dataset. Got 69 out of 158 images correctly (43.671%). Epoch Loss: 0.728\n",
            "   -- Val Dataset. Got 13 out of 22 images correctly (59.091%)\n",
            "Epoch number 29\n",
            "   -- Training Dataset. Got 68 out of 158 images correctly (43.038%). Epoch Loss: 0.715\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 30\n",
            "   -- Training Dataset. Got 86 out of 158 images correctly (54.430%). Epoch Loss: 0.686\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 31\n",
            "   -- Training Dataset. Got 81 out of 158 images correctly (51.266%). Epoch Loss: 0.727\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 32\n",
            "   -- Training Dataset. Got 80 out of 158 images correctly (50.633%). Epoch Loss: 0.708\n",
            "   -- Val Dataset. Got 14 out of 22 images correctly (63.636%)\n",
            "Epoch number 33\n",
            "   -- Training Dataset. Got 88 out of 158 images correctly (55.696%). Epoch Loss: 0.688\n",
            "   -- Val Dataset. Got 15 out of 22 images correctly (68.182%)\n",
            "Epoch number 34\n",
            "   -- Training Dataset. Got 101 out of 158 images correctly (63.924%). Epoch Loss: 0.665\n",
            "   -- Val Dataset. Got 11 out of 22 images correctly (50.000%)\n",
            "Epoch number 35\n",
            "   -- Training Dataset. Got 91 out of 158 images correctly (57.595%). Epoch Loss: 0.694\n",
            "   -- Val Dataset. Got 12 out of 22 images correctly (54.545%)\n",
            "Epoch number 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c799fdb5cece46b1acc5a99cc49a6a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd97ebc357964538a2eb47c809909f05",
              "IPY_MODEL_41366509067d4b4c8ad108735ce1f6aa",
              "IPY_MODEL_6b624b1f0a9e498abb41131ed3078d98"
            ],
            "layout": "IPY_MODEL_1e3aa6618aea4ced8c788eb63a319d58"
          }
        },
        "bd97ebc357964538a2eb47c809909f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c525bd8bdb284129b7bbc4807efb1a56",
            "placeholder": "​",
            "style": "IPY_MODEL_f5f722c148d44fa4ba7a5ecec25cd87a",
            "value": "100%"
          }
        },
        "41366509067d4b4c8ad108735ce1f6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d9f521f65754eddb489df920aeb8f27",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5440fda81d4464e9458f4bed621e7ed",
            "value": 102530333
          }
        },
        "6b624b1f0a9e498abb41131ed3078d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f5463aaed164dc3b1bd67713687256b",
            "placeholder": "​",
            "style": "IPY_MODEL_497a3ff59bec43ba810cf62a21bebfcc",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 249MB/s]"
          }
        },
        "1e3aa6618aea4ced8c788eb63a319d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c525bd8bdb284129b7bbc4807efb1a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5f722c148d44fa4ba7a5ecec25cd87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d9f521f65754eddb489df920aeb8f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5440fda81d4464e9458f4bed621e7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f5463aaed164dc3b1bd67713687256b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497a3ff59bec43ba810cf62a21bebfcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}