{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCL_kEI5MaBQ"
      },
      "source": [
        "#**Drive mount**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPcE5wbH8VwQ",
        "outputId": "b32413f0-e6db-4e3f-81d6-3f9e789ff15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8np-oJYrXe2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import sklearn.metrics\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from google.colab.patches import cv2_imshow\n",
        "import skimage\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import torch\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhLUp9uslm0q"
      },
      "outputs": [],
      "source": [
        "SUBJECTS_FOLDER = '/content/drive/MyDrive/Tirocinio/Datasets/Social memory cuing full dataset/derivatives/EEGPreprocessedDataTableStudy'\n",
        "SINGLE_SUBJECT = os.path.join(SUBJECTS_FOLDER, \"sub-34/ProcessedData/data_ica.mat\")\n",
        "SUBJECTS = [ name for name in os.listdir(SUBJECTS_FOLDER) if os.path.isdir(os.path.join(SUBJECTS_FOLDER, name)) ]\n",
        "DATA = \"ProcessedData/data_ica.mat\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-tYE8Qrls4H"
      },
      "outputs": [],
      "source": [
        "mat = scipy.io.loadmat(SINGLE_SUBJECT)\n",
        "trial = mat['trial']\n",
        "trialinfo = mat['trialinfo']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP-f0Bx8l37k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c017e5b-ec01-43cf-a49e-89b49cf639e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(125, 29)\n"
          ]
        }
      ],
      "source": [
        "trial = np.transpose(np.squeeze(trial))\n",
        "trials = []\n",
        "labels = []\n",
        "NUM_CHANNELS = 29\n",
        "NUM_TRIAL = 224\n",
        "cueing_fase = range(1250,1750)\n",
        "#encoding_fase = range()\n",
        "for i, t in enumerate(trial):\n",
        "  trials.append(t[ :NUM_CHANNELS, cueing_fase])\n",
        "  labels.append(trialinfo[i, 5]-1)  #zero is stick, one is avatar --- the -1 to have labels with 0 or 1 values (in dataset are 1 and 2)\n",
        "\n",
        "#trials = list(np.transpose(trials, [0, 2, 1]))\n",
        "trials = list(signal.decimate(np.transpose(trials, [0, 2, 1]), 4, axis = 1)) #downsampling\n",
        "\n",
        "\n",
        "print(np.shape(trials[0]))\n",
        "#print(np.shape(labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape: ', np.shape(trials))\n",
        "print()\n",
        "print(type(trials))\n",
        "print(type(trials[0][0][0]))\n",
        "print(trials[0][0])\n",
        "print(np.shape(trials[0][0]))"
      ],
      "metadata": {
        "id": "l4RbLjN7lXlr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fbe1e1-2a81-44bc-8d39-dc1ef3326b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape:  (224, 125, 29)\n",
            "\n",
            "<class 'list'>\n",
            "<class 'numpy.float64'>\n",
            "[-17.58227112 -31.03411281 -24.89601226  10.98182721 -28.56739956\n",
            " -11.88975447 -14.37107544  17.39609174   0.98526032 -10.10128604\n",
            " -17.31733843   3.36181593  18.35422871  -2.90500785  -9.79099322\n",
            " -10.68553525  16.551753     7.84930119   0.03228607  -8.05575676\n",
            "   1.12886725   5.64164922  13.76585772  -1.48080577   6.21061471\n",
            "  24.28707284   4.52834584   5.33621926  16.68523822]\n",
            "(29,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "1ZQr5eALwKtP",
        "outputId": "d28b9504-8b61-4dfd-fa7f-618ddc7f6421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub Pari\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f693e37e510>]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "if labels[0] == 0 and labels[112] == 1:\n",
        "  print('Sub Dispari')\n",
        "\n",
        "if labels[0] == 1 and labels[112] == 0:\n",
        "  print('Sub Pari')\n",
        "\n",
        "print()\n",
        "print(type(trials[0]))\n",
        "\n",
        "plt.plot(trials[1][:, 0])\n",
        "plt.plot(trials[0][:, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmCaqdnVeIQs"
      },
      "source": [
        "##**Normalizzazione**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq7u3DzteGA_"
      },
      "outputs": [],
      "source": [
        "def _normalize_trial(trial):\n",
        "  trial_avg = np.mean(trial)\n",
        "  trial_std = np.std(trial)\n",
        "\n",
        "  trial = (trial - trial_avg)/trial_std\n",
        "  return trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqByn23Tw2Nv"
      },
      "source": [
        "##**Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upzl0Jm3w1XH"
      },
      "outputs": [],
      "source": [
        "class EEG_dataset(Dataset):\n",
        "\n",
        "    def __init__(self, trials, labels):\n",
        "        self.trials = trials\n",
        "        self.labels = labels\n",
        "        self._init_data()\n",
        "\n",
        "    def _init_data(self):\n",
        "        self.samples = []\n",
        "        for i, trial in enumerate(self.trials):\n",
        "            self.samples.append((trial, self.labels[i]))    \n",
        "    \n",
        "    def __len__(self):\n",
        "      return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      '''\n",
        "      if self.labels[idx] == 3: #passive state\n",
        "        label = torch.tensor(1, dtype=torch.long)\n",
        "      else:\n",
        "        label = torch.tensor(0, dtype=torch.long)\n",
        "      '''\n",
        "      return torch.tensor(_normalize_trial(self.trials[idx])), torch.tensor(self.labels[idx], dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQxZabYiQu3C",
        "outputId": "90cf672c-b6d0-4047-b511-60086043a330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "if labels[0] == 0 and labels[112] == 1:\n",
        "  print('Sub Dispari')\n",
        "  NONSOCIAL_RANGE = range(0,112)\n",
        "  SOCIAL_RANGE = range(112,224)\n",
        "  TRAIN_RANGE_S = range(0,79)\n",
        "  TRAIN_RANGE_NONS = range(112,191)\n",
        "  TEST_RANGE_S = range(79,101)\n",
        "  TEST_RANGE_NONS = range(191,213)\n",
        "  VAL_RANGE_S = range(101,112)\n",
        "  VAL_RANGE_NONS = range(213,224)\n",
        "\n",
        "\n",
        "  nonsoc_trials = []\n",
        "  for nonsoc in NONSOCIAL_RANGE:\n",
        "    nonsoc_trials.append(trials[nonsoc])\n",
        "  seed = 42\n",
        "  random.seed(seed)\n",
        "  random.shuffle(nonsoc_trials)\n",
        "\n",
        "  soc_trials = []\n",
        "  for soc in SOCIAL_RANGE:\n",
        "    soc_trials.append(trials[soc])\n",
        "  seed = 42\n",
        "  random.seed(seed)\n",
        "  random.shuffle(soc_trials)\n",
        "\n",
        "  trials = nonsoc_trials + soc_trials\n",
        "\n",
        "  train_data = []\n",
        "  train_labels = []\n",
        "  for tns in TRAIN_RANGE_NONS:\n",
        "    train_data.append(trials[tns])\n",
        "    train_labels.append(labels[tns])\n",
        "  for ts in TRAIN_RANGE_S:\n",
        "    train_data.append(trials[ts])\n",
        "    train_labels.append(labels[ts])\n",
        "\n",
        "  test_data = []\n",
        "  test_labels = []\n",
        "  for tens in TEST_RANGE_NONS:\n",
        "    test_data.append(trials[tens])\n",
        "    test_labels.append(labels[tens])\n",
        "  for tes in TEST_RANGE_S:\n",
        "    test_data.append(trials[tes])\n",
        "    test_labels.append(labels[tes])\n",
        "\n",
        "  val_data = []\n",
        "  val_labels = []\n",
        "  for vns in VAL_RANGE_NONS:\n",
        "    val_data.append(trials[vns])\n",
        "    val_labels.append(labels[vns])\n",
        "  for vs in VAL_RANGE_S:\n",
        "    val_data.append(trials[vs])\n",
        "    val_labels.append(labels[vs])\n",
        "\n",
        "# ----- PARI ---------\n",
        "\n",
        "if labels[0] == 1 and labels[112] == 0:\n",
        "  print('Sub Pari')\n",
        "  SOCIAL_RANGE = range(0,112)\n",
        "  NONSOCIAL_RANGE = range(112,224)\n",
        "\n",
        "  TRAIN_RANGE_S = range(0,79)\n",
        "  TRAIN_RANGE_NONS = range(112,191)\n",
        "\n",
        "  TEST_RANGE_S = range(79,101)\n",
        "  TEST_RANGE_NONS = range(191,213)\n",
        "\n",
        "  VAL_RANGE_S = range(101,112)\n",
        "  VAL_RANGE_NONS = range(213,224)\n",
        "\n",
        "\n",
        "  soc_trials = []\n",
        "  for soc in SOCIAL_RANGE:\n",
        "    soc_trials.append(trials[soc])\n",
        "  seed = 42\n",
        "  random.seed(seed)\n",
        "  random.shuffle(soc_trials)\n",
        "\n",
        "  nonsoc_trials = []\n",
        "  for nonsoc in NONSOCIAL_RANGE:\n",
        "    nonsoc_trials.append(trials[nonsoc])\n",
        "  seed = 42\n",
        "  random.seed(seed)\n",
        "  random.shuffle(nonsoc_trials)\n",
        "\n",
        "  trials = soc_trials + nonsoc_trials\n",
        "\n",
        "  train_data = []\n",
        "  train_labels = []\n",
        "\n",
        "  for ts in TRAIN_RANGE_S:\n",
        "    train_data.append(trials[ts])\n",
        "    train_labels.append(labels[ts])\n",
        "  for tns in TRAIN_RANGE_NONS:\n",
        "    train_data.append(trials[tns])\n",
        "    train_labels.append(labels[tns])\n",
        "\n",
        "  test_data = []\n",
        "  test_labels = []\n",
        "\n",
        "\n",
        "  for tes in TEST_RANGE_S:\n",
        "    test_data.append(trials[tes])\n",
        "    test_labels.append(labels[tes])\n",
        "  for tens in TEST_RANGE_NONS:\n",
        "    test_data.append(trials[tens])\n",
        "    test_labels.append(labels[tens])\n",
        "\n",
        "  val_data = []\n",
        "  val_labels = []\n",
        "\n",
        "\n",
        "  for vs in VAL_RANGE_S:\n",
        "    val_data.append(trials[vs])\n",
        "    val_labels.append(labels[vs])\n",
        "  for vns in VAL_RANGE_NONS:\n",
        "    val_data.append(trials[vns])\n",
        "    val_labels.append(labels[vns])\n",
        "\n",
        "print(f'Train Data Shape: ', np.shape(train_data))\n",
        "print(f'Test Data Shape: ', np.shape(test_data))\n",
        "print(f'Val Data Shape: ', np.shape(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wADm7wwbBS5E",
        "outputId": "74df5666-8ab1-4f97-b04d-bf18f9cb01f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub Pari\n",
            "Train Data Shape:  (158, 125, 29)\n",
            "Test Data Shape:  (44, 125, 29)\n",
            "Val Data Shape:  (22, 125, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train Imbalance: ', train_labels.count(1)/len(train_labels))\n",
        "print(f'Test Imbalance: ', test_labels.count(1)/len(test_labels))\n",
        "print(f'Val Imbalance: ', val_labels.count(1)/len(val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7jfv-b_W_iA",
        "outputId": "80fb8e53-85fa-410a-be9f-8a9f29890118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Imbalance:  0.5\n",
            "Test Imbalance:  0.5\n",
            "Val Imbalance:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twcRSiw_zhXn"
      },
      "outputs": [],
      "source": [
        "train_dataset = EEG_dataset(train_data, train_labels)\n",
        "val_dataset = EEG_dataset(val_data, val_labels)\n",
        "test_dataset = EEG_dataset(test_data, test_labels)\n",
        "\n",
        "#print(next(iter(train_dataset)))\n",
        "#print(next(iter(val_dataset)))\n",
        "#print(next(iter(test_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFLFTPxvChli"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 1, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eYkdSaKzV7O",
        "outputId": "42fec8ef-55b8-46cc-f9a4-2ea04c156e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "Train batch type:  <class 'torch.Tensor'>\n",
            "Test batch type:  <class 'torch.Tensor'>\n",
            "Val batch type:  <class 'torch.Tensor'>\n",
            "torch.Size([1, 125, 29])\n",
            "torch.Size([1, 1, 125, 29])\n"
          ]
        }
      ],
      "source": [
        "train_batch = next(iter(train_loader))\n",
        "test_batch = next(iter(test_loader))\n",
        "val_batch = next(iter(val_loader))\n",
        "#print(train_batch)\n",
        "print(type(train_batch))\n",
        "print(f'Train batch type: ', type(train_batch[0]))\n",
        "print(f'Test batch type: ', type(test_batch[0]))\n",
        "print(f'Val batch type: ', type(val_batch[0]))\n",
        "print(train_batch[0].shape)\n",
        "train_batch[0] = torch.unsqueeze(train_batch[0], 0)\n",
        "print(train_batch[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuN3wXUb5Xal"
      },
      "outputs": [],
      "source": [
        "def set_device():\n",
        "  if torch.cuda.is_available():\n",
        "    dev = \"cuda:0\"\n",
        "  else:\n",
        "    dev = \"cpu\"\n",
        "  return torch.device(dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt30YSs14y3s"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FYUOo9TzdlZ"
      },
      "outputs": [],
      "source": [
        "plot_train_acc = []\n",
        "plot_val_acc = []\n",
        "plot_train_loss = []\n",
        "\n",
        "def train_nn(model, train_loader, val_loader, criterion, optimizer, n_epochs):\n",
        "  device = set_device()\n",
        "  best_acc = 0\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    print(\"Epoch number %d\" %(epoch + 1))\n",
        "    model.train()\n",
        "    curr_loss = 0.0\n",
        "    curr_true = 0.0\n",
        "    total = 0\n",
        "    for batch in train_loader:\n",
        "      #print(type(batch))\n",
        "      trial, labels = batch\n",
        "      #print('Labels --->', labels)\n",
        "      #print('Labels type --->', type(labels))\n",
        "      #print('Prima cambio -->  ', images.dtype)\n",
        "      #images = images.type('torch.DoubleTensor') \n",
        "      #print('Dopo cambio -->  ', images.dtype)\n",
        "      #images = torch.tensor(images)\n",
        "      #labels = torch.tensor(labels)\n",
        "      #images = images.to(device)\n",
        "      #labels = labels.to(device)\n",
        "      total += labels.size(0) #perche anche se il batch  da 32 l'ultimo potrebbe essere pi piccolo\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #print('Shape trial prima di passarle al model', np.shape(trial))\n",
        "      #outputs = model(trial)\n",
        "      #print('Outputs prima --->', outputs)\n",
        "      outputs = model(trial.unsqueeze(1).float())\n",
        "      #print('Outputs prima--->', np.shape(outputs))\n",
        "      #print(type(outputs))\n",
        "\n",
        "      predicted = torch.round(outputs) #l'1 specifica il one dimension reduce\n",
        "\n",
        "\n",
        "      #print('Outputs -->', np.shape(outputs))\n",
        "      #print('Labels -->', np.shape(labels))\n",
        "      loss = criterion(outputs, labels.float())\n",
        "\n",
        "      loss.backward()\n",
        "        \n",
        "      optimizer.step()\n",
        "\n",
        "      curr_loss += loss.item()\n",
        "      curr_true += (labels==predicted).sum().item()\n",
        "\n",
        "    \n",
        "    epoch_loss = curr_loss/len(train_loader)\n",
        "    epoch_accuracy = (curr_true/total)*100\n",
        "    plot_train_acc.append(epoch_accuracy)\n",
        "    plot_train_loss.append(epoch_loss)\n",
        "    #scheduler.step()\n",
        "\n",
        "    print(\"   -- Training Dataset. Got %d out of %d trials correctly (%.3f%%). Epoch Loss: %.3f\" %(curr_true, total, epoch_accuracy, epoch_loss))\n",
        "\n",
        "    val_acc = evaluate_model_val(model, val_loader)\n",
        "    plot_val_acc.append(val_acc)\n",
        "\n",
        "\n",
        "    if(val_acc >= best_acc):\n",
        "      best_acc = val_acc\n",
        "      save_checkpoint(model, epoch, optimizer, best_acc)\n",
        "      save_best_model(model)\n",
        "\n",
        "  print(\"\\n  -- Done!\")\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcoHyZn-5dHI"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, epoch, optimizer, best_acc):\n",
        "  state = {\n",
        "      'epoch': epoch + 1,\n",
        "      'model': model.state_dict(),\n",
        "      'best accuracy': best_acc,\n",
        "      'optimizer': optimizer.state_dict(),\n",
        "      'comments': 'sub 33 NORM SGD'\n",
        "  }\n",
        "  torch.save(state, 'checkpoint.pth.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1D2EBxM5eAJ"
      },
      "outputs": [],
      "source": [
        "def save_best_model(model):\n",
        "  torch.save(model, 'best_model.pth.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMnNvcX95krI"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_val(model, val_loader):\n",
        "  model.eval()\n",
        "  true_predicted_on_epoch = 0\n",
        "  total = 0\n",
        "  device = set_device()\n",
        "\n",
        "  with torch.no_grad(): #reduce memory usage and speed up the evaluation (no backpropagation che non si fa sul test)\n",
        "    for batch in val_loader:\n",
        "      trial, labels = batch\n",
        "      trial = trial.to(device)\n",
        "      labels = labels.to(device)\n",
        "      total += labels.size(0)\n",
        "\n",
        "      outputs = model(trial.unsqueeze(1).float())\n",
        "\n",
        "      predicted = torch.round(outputs)\n",
        "\n",
        "      true_predicted_on_epoch += (predicted==labels).sum().item()\n",
        "\n",
        "    epoch_accuracy = (true_predicted_on_epoch/total)*100\n",
        "\n",
        "    print(\"   -- Val Dataset. Got %d out of %d trials correctly (%.3f%%)\" %(true_predicted_on_epoch, total, epoch_accuracy))\n",
        "\n",
        "  return epoch_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AR1FrhcuB-hz"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "NUM_CHANNELS = 29\n",
        "device = set_device()\n",
        "loss_fn = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVUwGxAeM-ZN"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules import dropout\n",
        "class OurNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(OurNet, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = (3, 3), stride = 4);\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 3, stride = None, padding = 0);\n",
        "        self.batch = nn.BatchNorm2d(num_features = 6);\n",
        "        #self.act_f = nn.Hardshrink();\n",
        "        self.act_f = nn.SELU();\n",
        "        #self.act_f = nn.GELU();\n",
        "        self.drop = nn.Dropout(p = 0.4)\n",
        "        self.lin = nn.Linear(in_features = 120, out_features = 80); #1x120\n",
        "        self.drop1 = nn.Dropout(p = 0.3);\n",
        "        #self.lstm = nn.LSTM(input_size = 128, hidden_size = 250)\n",
        "        self.lstm = nn.GRU(input_size = 80, hidden_size = 60)\n",
        "\n",
        "        self.lastlayer = nn.Linear(in_features = 60, out_features = 1);\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.conv(x);\n",
        "        #print('Dopo conv --> ', hidden.size())\n",
        "        #hidden = hidden.view(hidden.size()[0], -1)\n",
        "        #hidden = torch.squeeze(hidden, dim = -1)\n",
        "        #print('Dopo squeeze --> ', hidden.size())\n",
        "        hidden = self.pool(hidden)\n",
        "        #print('Dopo MaxPool1D --> ', hidden.size())\n",
        "        hidden = self.batch(hidden)\n",
        "        #print('Dopo Batch --> ', hidden.size())\n",
        "        hidden = self.act_f(hidden)\n",
        "        hidden = self.drop(hidden)\n",
        "        hidden = torch.flatten(hidden, start_dim = 1 , end_dim = -1)\n",
        "        #print('Dopo Flatten --> ', hidden.size())\n",
        "        hidden = self.lin(hidden)\n",
        "        #print('Dopo lin --> ', hidden.size())\n",
        "        hidden = self.drop1(hidden)\n",
        "        hidden,_ = self.lstm(hidden)\n",
        "        #print('Dopo LSTM --> ', np.shape(hidden))\n",
        "        out = self.lastlayer(hidden)\n",
        "        #print('Dopo ultimo Lin --> ',out.size())\n",
        "        out = torch.squeeze(out, dim = -1)\n",
        "        #print('Dopo squeeze --> ',out.size())\n",
        "        #print()\n",
        "        out = torch.sigmoid(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "model = OurNet()"
      ],
      "metadata": {
        "id": "s54NvzMBD6JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=1e-5, dampening=0.1)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "train_nn(model, train_loader, val_loader, loss_fn, optimizer, 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrxbyWFSHrps",
        "outputId": "b0f8d147-cf97-44cb-ca66-197f5dd4e261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch number 1\n",
            "   -- Training Dataset. Got 84 out of 158 trials correctly (53.165%). Epoch Loss: 0.694\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 2\n",
            "   -- Training Dataset. Got 84 out of 158 trials correctly (53.165%). Epoch Loss: 0.687\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 3\n",
            "   -- Training Dataset. Got 81 out of 158 trials correctly (51.266%). Epoch Loss: 0.692\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 4\n",
            "   -- Training Dataset. Got 83 out of 158 trials correctly (52.532%). Epoch Loss: 0.684\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 5\n",
            "   -- Training Dataset. Got 89 out of 158 trials correctly (56.329%). Epoch Loss: 0.677\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 6\n",
            "   -- Training Dataset. Got 88 out of 158 trials correctly (55.696%). Epoch Loss: 0.681\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 7\n",
            "   -- Training Dataset. Got 93 out of 158 trials correctly (58.861%). Epoch Loss: 0.682\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 8\n",
            "   -- Training Dataset. Got 88 out of 158 trials correctly (55.696%). Epoch Loss: 0.687\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 9\n",
            "   -- Training Dataset. Got 96 out of 158 trials correctly (60.759%). Epoch Loss: 0.674\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 10\n",
            "   -- Training Dataset. Got 88 out of 158 trials correctly (55.696%). Epoch Loss: 0.675\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 11\n",
            "   -- Training Dataset. Got 89 out of 158 trials correctly (56.329%). Epoch Loss: 0.680\n",
            "   -- Val Dataset. Got 12 out of 22 trials correctly (54.545%)\n",
            "Epoch number 12\n",
            "   -- Training Dataset. Got 86 out of 158 trials correctly (54.430%). Epoch Loss: 0.676\n",
            "   -- Val Dataset. Got 12 out of 22 trials correctly (54.545%)\n",
            "Epoch number 13\n",
            "   -- Training Dataset. Got 96 out of 158 trials correctly (60.759%). Epoch Loss: 0.669\n",
            "   -- Val Dataset. Got 12 out of 22 trials correctly (54.545%)\n",
            "Epoch number 14\n",
            "   -- Training Dataset. Got 96 out of 158 trials correctly (60.759%). Epoch Loss: 0.679\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 15\n",
            "   -- Training Dataset. Got 101 out of 158 trials correctly (63.924%). Epoch Loss: 0.669\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 16\n",
            "   -- Training Dataset. Got 104 out of 158 trials correctly (65.823%). Epoch Loss: 0.663\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 17\n",
            "   -- Training Dataset. Got 102 out of 158 trials correctly (64.557%). Epoch Loss: 0.663\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 18\n",
            "   -- Training Dataset. Got 100 out of 158 trials correctly (63.291%). Epoch Loss: 0.660\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 19\n",
            "   -- Training Dataset. Got 92 out of 158 trials correctly (58.228%). Epoch Loss: 0.673\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 20\n",
            "   -- Training Dataset. Got 106 out of 158 trials correctly (67.089%). Epoch Loss: 0.656\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 21\n",
            "   -- Training Dataset. Got 99 out of 158 trials correctly (62.658%). Epoch Loss: 0.665\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 22\n",
            "   -- Training Dataset. Got 87 out of 158 trials correctly (55.063%). Epoch Loss: 0.673\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 23\n",
            "   -- Training Dataset. Got 100 out of 158 trials correctly (63.291%). Epoch Loss: 0.656\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 24\n",
            "   -- Training Dataset. Got 107 out of 158 trials correctly (67.722%). Epoch Loss: 0.651\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 25\n",
            "   -- Training Dataset. Got 98 out of 158 trials correctly (62.025%). Epoch Loss: 0.665\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 26\n",
            "   -- Training Dataset. Got 108 out of 158 trials correctly (68.354%). Epoch Loss: 0.637\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 27\n",
            "   -- Training Dataset. Got 100 out of 158 trials correctly (63.291%). Epoch Loss: 0.647\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 28\n",
            "   -- Training Dataset. Got 101 out of 158 trials correctly (63.924%). Epoch Loss: 0.646\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 29\n",
            "   -- Training Dataset. Got 109 out of 158 trials correctly (68.987%). Epoch Loss: 0.638\n",
            "   -- Val Dataset. Got 10 out of 22 trials correctly (45.455%)\n",
            "Epoch number 30\n",
            "   -- Training Dataset. Got 96 out of 158 trials correctly (60.759%). Epoch Loss: 0.651\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 31\n",
            "   -- Training Dataset. Got 104 out of 158 trials correctly (65.823%). Epoch Loss: 0.640\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 32\n",
            "   -- Training Dataset. Got 107 out of 158 trials correctly (67.722%). Epoch Loss: 0.641\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 33\n",
            "   -- Training Dataset. Got 111 out of 158 trials correctly (70.253%). Epoch Loss: 0.623\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 34\n",
            "   -- Training Dataset. Got 108 out of 158 trials correctly (68.354%). Epoch Loss: 0.644\n",
            "   -- Val Dataset. Got 11 out of 22 trials correctly (50.000%)\n",
            "Epoch number 35\n",
            "   -- Training Dataset. Got 111 out of 158 trials correctly (70.253%). Epoch Loss: 0.625\n",
            "   -- Val Dataset. Got 12 out of 22 trials correctly (54.545%)\n",
            "Epoch number 36\n",
            "   -- Training Dataset. Got 113 out of 158 trials correctly (71.519%). Epoch Loss: 0.633\n",
            "   -- Val Dataset. Got 12 out of 22 trials correctly (54.545%)\n",
            "Epoch number 37\n",
            "   -- Training Dataset. Got 108 out of 158 trials correctly (68.354%). Epoch Loss: 0.615\n",
            "   -- Val Dataset. Got 12 out of 22 trials correctly (54.545%)\n",
            "Epoch number 38\n",
            "   -- Training Dataset. Got 109 out of 158 trials correctly (68.987%). Epoch Loss: 0.620\n",
            "   -- Val Dataset. Got 12 out of 22 trials correctly (54.545%)\n",
            "Epoch number 39\n",
            "   -- Training Dataset. Got 108 out of 158 trials correctly (68.354%). Epoch Loss: 0.614\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 40\n",
            "   -- Training Dataset. Got 113 out of 158 trials correctly (71.519%). Epoch Loss: 0.590\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 41\n",
            "   -- Training Dataset. Got 109 out of 158 trials correctly (68.987%). Epoch Loss: 0.621\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 42\n",
            "   -- Training Dataset. Got 110 out of 158 trials correctly (69.620%). Epoch Loss: 0.614\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 43\n",
            "   -- Training Dataset. Got 108 out of 158 trials correctly (68.354%). Epoch Loss: 0.609\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 44\n",
            "   -- Training Dataset. Got 107 out of 158 trials correctly (67.722%). Epoch Loss: 0.606\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 45\n",
            "   -- Training Dataset. Got 122 out of 158 trials correctly (77.215%). Epoch Loss: 0.581\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 46\n",
            "   -- Training Dataset. Got 112 out of 158 trials correctly (70.886%). Epoch Loss: 0.580\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 47\n",
            "   -- Training Dataset. Got 115 out of 158 trials correctly (72.785%). Epoch Loss: 0.573\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 48\n",
            "   -- Training Dataset. Got 118 out of 158 trials correctly (74.684%). Epoch Loss: 0.584\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 49\n",
            "   -- Training Dataset. Got 123 out of 158 trials correctly (77.848%). Epoch Loss: 0.565\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 50\n",
            "   -- Training Dataset. Got 118 out of 158 trials correctly (74.684%). Epoch Loss: 0.573\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 51\n",
            "   -- Training Dataset. Got 113 out of 158 trials correctly (71.519%). Epoch Loss: 0.555\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 52\n",
            "   -- Training Dataset. Got 125 out of 158 trials correctly (79.114%). Epoch Loss: 0.551\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 53\n",
            "   -- Training Dataset. Got 111 out of 158 trials correctly (70.253%). Epoch Loss: 0.589\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 54\n",
            "   -- Training Dataset. Got 115 out of 158 trials correctly (72.785%). Epoch Loss: 0.543\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 55\n",
            "   -- Training Dataset. Got 121 out of 158 trials correctly (76.582%). Epoch Loss: 0.537\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 56\n",
            "   -- Training Dataset. Got 120 out of 158 trials correctly (75.949%). Epoch Loss: 0.545\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 57\n",
            "   -- Training Dataset. Got 118 out of 158 trials correctly (74.684%). Epoch Loss: 0.542\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 58\n",
            "   -- Training Dataset. Got 123 out of 158 trials correctly (77.848%). Epoch Loss: 0.530\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 59\n",
            "   -- Training Dataset. Got 123 out of 158 trials correctly (77.848%). Epoch Loss: 0.509\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 60\n",
            "   -- Training Dataset. Got 121 out of 158 trials correctly (76.582%). Epoch Loss: 0.516\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 61\n",
            "   -- Training Dataset. Got 121 out of 158 trials correctly (76.582%). Epoch Loss: 0.519\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 62\n",
            "   -- Training Dataset. Got 122 out of 158 trials correctly (77.215%). Epoch Loss: 0.487\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 63\n",
            "   -- Training Dataset. Got 123 out of 158 trials correctly (77.848%). Epoch Loss: 0.495\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 64\n",
            "   -- Training Dataset. Got 123 out of 158 trials correctly (77.848%). Epoch Loss: 0.478\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 65\n",
            "   -- Training Dataset. Got 127 out of 158 trials correctly (80.380%). Epoch Loss: 0.476\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 66\n",
            "   -- Training Dataset. Got 125 out of 158 trials correctly (79.114%). Epoch Loss: 0.484\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 67\n",
            "   -- Training Dataset. Got 128 out of 158 trials correctly (81.013%). Epoch Loss: 0.461\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 68\n",
            "   -- Training Dataset. Got 121 out of 158 trials correctly (76.582%). Epoch Loss: 0.477\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 69\n",
            "   -- Training Dataset. Got 121 out of 158 trials correctly (76.582%). Epoch Loss: 0.485\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 70\n",
            "   -- Training Dataset. Got 126 out of 158 trials correctly (79.747%). Epoch Loss: 0.464\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 71\n",
            "   -- Training Dataset. Got 127 out of 158 trials correctly (80.380%). Epoch Loss: 0.481\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 72\n",
            "   -- Training Dataset. Got 137 out of 158 trials correctly (86.709%). Epoch Loss: 0.459\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 73\n",
            "   -- Training Dataset. Got 128 out of 158 trials correctly (81.013%). Epoch Loss: 0.466\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 74\n",
            "   -- Training Dataset. Got 132 out of 158 trials correctly (83.544%). Epoch Loss: 0.434\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 75\n",
            "   -- Training Dataset. Got 124 out of 158 trials correctly (78.481%). Epoch Loss: 0.492\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 76\n",
            "   -- Training Dataset. Got 122 out of 158 trials correctly (77.215%). Epoch Loss: 0.452\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 77\n",
            "   -- Training Dataset. Got 129 out of 158 trials correctly (81.646%). Epoch Loss: 0.419\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 78\n",
            "   -- Training Dataset. Got 127 out of 158 trials correctly (80.380%). Epoch Loss: 0.430\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 79\n",
            "   -- Training Dataset. Got 124 out of 158 trials correctly (78.481%). Epoch Loss: 0.454\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 80\n",
            "   -- Training Dataset. Got 130 out of 158 trials correctly (82.278%). Epoch Loss: 0.434\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 81\n",
            "   -- Training Dataset. Got 128 out of 158 trials correctly (81.013%). Epoch Loss: 0.428\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 82\n",
            "   -- Training Dataset. Got 127 out of 158 trials correctly (80.380%). Epoch Loss: 0.423\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 83\n",
            "   -- Training Dataset. Got 129 out of 158 trials correctly (81.646%). Epoch Loss: 0.404\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 84\n",
            "   -- Training Dataset. Got 128 out of 158 trials correctly (81.013%). Epoch Loss: 0.411\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 85\n",
            "   -- Training Dataset. Got 129 out of 158 trials correctly (81.646%). Epoch Loss: 0.380\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 86\n",
            "   -- Training Dataset. Got 124 out of 158 trials correctly (78.481%). Epoch Loss: 0.458\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 87\n",
            "   -- Training Dataset. Got 127 out of 158 trials correctly (80.380%). Epoch Loss: 0.432\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 88\n",
            "   -- Training Dataset. Got 127 out of 158 trials correctly (80.380%). Epoch Loss: 0.416\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 89\n",
            "   -- Training Dataset. Got 133 out of 158 trials correctly (84.177%). Epoch Loss: 0.401\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 90\n",
            "   -- Training Dataset. Got 124 out of 158 trials correctly (78.481%). Epoch Loss: 0.447\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 91\n",
            "   -- Training Dataset. Got 127 out of 158 trials correctly (80.380%). Epoch Loss: 0.428\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 92\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.393\n",
            "   -- Val Dataset. Got 19 out of 22 trials correctly (86.364%)\n",
            "Epoch number 93\n",
            "   -- Training Dataset. Got 129 out of 158 trials correctly (81.646%). Epoch Loss: 0.402\n",
            "   -- Val Dataset. Got 19 out of 22 trials correctly (86.364%)\n",
            "Epoch number 94\n",
            "   -- Training Dataset. Got 131 out of 158 trials correctly (82.911%). Epoch Loss: 0.407\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 95\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.395\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 96\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.350\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 97\n",
            "   -- Training Dataset. Got 137 out of 158 trials correctly (86.709%). Epoch Loss: 0.366\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 98\n",
            "   -- Training Dataset. Got 131 out of 158 trials correctly (82.911%). Epoch Loss: 0.377\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 99\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.359\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 100\n",
            "   -- Training Dataset. Got 137 out of 158 trials correctly (86.709%). Epoch Loss: 0.329\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 101\n",
            "   -- Training Dataset. Got 132 out of 158 trials correctly (83.544%). Epoch Loss: 0.372\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 102\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.363\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 103\n",
            "   -- Training Dataset. Got 133 out of 158 trials correctly (84.177%). Epoch Loss: 0.382\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 104\n",
            "   -- Training Dataset. Got 129 out of 158 trials correctly (81.646%). Epoch Loss: 0.420\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 105\n",
            "   -- Training Dataset. Got 140 out of 158 trials correctly (88.608%). Epoch Loss: 0.293\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 106\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.335\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 107\n",
            "   -- Training Dataset. Got 129 out of 158 trials correctly (81.646%). Epoch Loss: 0.372\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 108\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.363\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 109\n",
            "   -- Training Dataset. Got 128 out of 158 trials correctly (81.013%). Epoch Loss: 0.411\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 110\n",
            "   -- Training Dataset. Got 129 out of 158 trials correctly (81.646%). Epoch Loss: 0.403\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 111\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.394\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 112\n",
            "   -- Training Dataset. Got 137 out of 158 trials correctly (86.709%). Epoch Loss: 0.335\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 113\n",
            "   -- Training Dataset. Got 133 out of 158 trials correctly (84.177%). Epoch Loss: 0.400\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 114\n",
            "   -- Training Dataset. Got 133 out of 158 trials correctly (84.177%). Epoch Loss: 0.377\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 115\n",
            "   -- Training Dataset. Got 129 out of 158 trials correctly (81.646%). Epoch Loss: 0.395\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 116\n",
            "   -- Training Dataset. Got 133 out of 158 trials correctly (84.177%). Epoch Loss: 0.331\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 117\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.353\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 118\n",
            "   -- Training Dataset. Got 132 out of 158 trials correctly (83.544%). Epoch Loss: 0.364\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 119\n",
            "   -- Training Dataset. Got 129 out of 158 trials correctly (81.646%). Epoch Loss: 0.386\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 120\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.324\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 121\n",
            "   -- Training Dataset. Got 132 out of 158 trials correctly (83.544%). Epoch Loss: 0.343\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 122\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.350\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 123\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.339\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 124\n",
            "   -- Training Dataset. Got 125 out of 158 trials correctly (79.114%). Epoch Loss: 0.400\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 125\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.336\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 126\n",
            "   -- Training Dataset. Got 131 out of 158 trials correctly (82.911%). Epoch Loss: 0.374\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 127\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.376\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 128\n",
            "   -- Training Dataset. Got 132 out of 158 trials correctly (83.544%). Epoch Loss: 0.344\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 129\n",
            "   -- Training Dataset. Got 136 out of 158 trials correctly (86.076%). Epoch Loss: 0.348\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 130\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.327\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 131\n",
            "   -- Training Dataset. Got 137 out of 158 trials correctly (86.709%). Epoch Loss: 0.322\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 132\n",
            "   -- Training Dataset. Got 137 out of 158 trials correctly (86.709%). Epoch Loss: 0.306\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 133\n",
            "   -- Training Dataset. Got 131 out of 158 trials correctly (82.911%). Epoch Loss: 0.335\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 134\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.348\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 135\n",
            "   -- Training Dataset. Got 132 out of 158 trials correctly (83.544%). Epoch Loss: 0.364\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 136\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.306\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 137\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.319\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 138\n",
            "   -- Training Dataset. Got 141 out of 158 trials correctly (89.241%). Epoch Loss: 0.283\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 139\n",
            "   -- Training Dataset. Got 140 out of 158 trials correctly (88.608%). Epoch Loss: 0.342\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 140\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.341\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 141\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.291\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 142\n",
            "   -- Training Dataset. Got 137 out of 158 trials correctly (86.709%). Epoch Loss: 0.341\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 143\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.385\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 144\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.334\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 145\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.282\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 146\n",
            "   -- Training Dataset. Got 142 out of 158 trials correctly (89.873%). Epoch Loss: 0.322\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 147\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.303\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 148\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.317\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 149\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.279\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 150\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.352\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 151\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.303\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 152\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.329\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 153\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.337\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 154\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.300\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 155\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.235\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 156\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.285\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 157\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.301\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 158\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.271\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 159\n",
            "   -- Training Dataset. Got 136 out of 158 trials correctly (86.076%). Epoch Loss: 0.330\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 160\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.318\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 161\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.323\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 162\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.315\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 163\n",
            "   -- Training Dataset. Got 131 out of 158 trials correctly (82.911%). Epoch Loss: 0.363\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 164\n",
            "   -- Training Dataset. Got 140 out of 158 trials correctly (88.608%). Epoch Loss: 0.294\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 165\n",
            "   -- Training Dataset. Got 142 out of 158 trials correctly (89.873%). Epoch Loss: 0.276\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 166\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.311\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 167\n",
            "   -- Training Dataset. Got 137 out of 158 trials correctly (86.709%). Epoch Loss: 0.300\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 168\n",
            "   -- Training Dataset. Got 137 out of 158 trials correctly (86.709%). Epoch Loss: 0.290\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 169\n",
            "   -- Training Dataset. Got 133 out of 158 trials correctly (84.177%). Epoch Loss: 0.337\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 170\n",
            "   -- Training Dataset. Got 132 out of 158 trials correctly (83.544%). Epoch Loss: 0.329\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 171\n",
            "   -- Training Dataset. Got 129 out of 158 trials correctly (81.646%). Epoch Loss: 0.336\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 172\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.291\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 173\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.260\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 174\n",
            "   -- Training Dataset. Got 140 out of 158 trials correctly (88.608%). Epoch Loss: 0.300\n",
            "   -- Val Dataset. Got 18 out of 22 trials correctly (81.818%)\n",
            "Epoch number 175\n",
            "   -- Training Dataset. Got 136 out of 158 trials correctly (86.076%). Epoch Loss: 0.293\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 176\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.344\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 177\n",
            "   -- Training Dataset. Got 140 out of 158 trials correctly (88.608%). Epoch Loss: 0.275\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 178\n",
            "   -- Training Dataset. Got 132 out of 158 trials correctly (83.544%). Epoch Loss: 0.332\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 179\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.281\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 180\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.218\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 181\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.309\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 182\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.284\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 183\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.282\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 184\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.280\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 185\n",
            "   -- Training Dataset. Got 141 out of 158 trials correctly (89.241%). Epoch Loss: 0.265\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 186\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.273\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 187\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.314\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 188\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.252\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 189\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.274\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 190\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.294\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 191\n",
            "   -- Training Dataset. Got 142 out of 158 trials correctly (89.873%). Epoch Loss: 0.264\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 192\n",
            "   -- Training Dataset. Got 142 out of 158 trials correctly (89.873%). Epoch Loss: 0.242\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 193\n",
            "   -- Training Dataset. Got 137 out of 158 trials correctly (86.709%). Epoch Loss: 0.298\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 194\n",
            "   -- Training Dataset. Got 142 out of 158 trials correctly (89.873%). Epoch Loss: 0.266\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 195\n",
            "   -- Training Dataset. Got 141 out of 158 trials correctly (89.241%). Epoch Loss: 0.262\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 196\n",
            "   -- Training Dataset. Got 136 out of 158 trials correctly (86.076%). Epoch Loss: 0.281\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 197\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.298\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 198\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.217\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 199\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.296\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 200\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.346\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 201\n",
            "   -- Training Dataset. Got 134 out of 158 trials correctly (84.810%). Epoch Loss: 0.322\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 202\n",
            "   -- Training Dataset. Got 140 out of 158 trials correctly (88.608%). Epoch Loss: 0.261\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 203\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.275\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 204\n",
            "   -- Training Dataset. Got 142 out of 158 trials correctly (89.873%). Epoch Loss: 0.248\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 205\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.294\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 206\n",
            "   -- Training Dataset. Got 140 out of 158 trials correctly (88.608%). Epoch Loss: 0.273\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 207\n",
            "   -- Training Dataset. Got 140 out of 158 trials correctly (88.608%). Epoch Loss: 0.250\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 208\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.229\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 209\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.184\n",
            "   -- Val Dataset. Got 13 out of 22 trials correctly (59.091%)\n",
            "Epoch number 210\n",
            "   -- Training Dataset. Got 141 out of 158 trials correctly (89.241%). Epoch Loss: 0.247\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 211\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.284\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 212\n",
            "   -- Training Dataset. Got 141 out of 158 trials correctly (89.241%). Epoch Loss: 0.268\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 213\n",
            "   -- Training Dataset. Got 141 out of 158 trials correctly (89.241%). Epoch Loss: 0.281\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 214\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.225\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 215\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.191\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 216\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.271\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 217\n",
            "   -- Training Dataset. Got 138 out of 158 trials correctly (87.342%). Epoch Loss: 0.251\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 218\n",
            "   -- Training Dataset. Got 140 out of 158 trials correctly (88.608%). Epoch Loss: 0.273\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 219\n",
            "   -- Training Dataset. Got 141 out of 158 trials correctly (89.241%). Epoch Loss: 0.244\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 220\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.211\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 221\n",
            "   -- Training Dataset. Got 141 out of 158 trials correctly (89.241%). Epoch Loss: 0.209\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 222\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.242\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 223\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.284\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 224\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.243\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 225\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.204\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 226\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.219\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 227\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.228\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 228\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.189\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 229\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.215\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 230\n",
            "   -- Training Dataset. Got 142 out of 158 trials correctly (89.873%). Epoch Loss: 0.239\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 231\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.211\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 232\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.166\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 233\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.207\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 234\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.261\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 235\n",
            "   -- Training Dataset. Got 142 out of 158 trials correctly (89.873%). Epoch Loss: 0.277\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 236\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.224\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 237\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.166\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 238\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.200\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 239\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.211\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 240\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.228\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 241\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.204\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 242\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.173\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 243\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.199\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 244\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.152\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 245\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.205\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 246\n",
            "   -- Training Dataset. Got 140 out of 158 trials correctly (88.608%). Epoch Loss: 0.212\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 247\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.193\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 248\n",
            "   -- Training Dataset. Got 141 out of 158 trials correctly (89.241%). Epoch Loss: 0.261\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 249\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.163\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 250\n",
            "   -- Training Dataset. Got 141 out of 158 trials correctly (89.241%). Epoch Loss: 0.232\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 251\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.206\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 252\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.191\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 253\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.214\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 254\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.182\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 255\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.218\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 256\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.194\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 257\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.202\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 258\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.196\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 259\n",
            "   -- Training Dataset. Got 135 out of 158 trials correctly (85.443%). Epoch Loss: 0.247\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 260\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.194\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 261\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.199\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 262\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.177\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 263\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.222\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 264\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.169\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 265\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.174\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 266\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.166\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 267\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.237\n",
            "   -- Val Dataset. Got 17 out of 22 trials correctly (77.273%)\n",
            "Epoch number 268\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.204\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 269\n",
            "   -- Training Dataset. Got 139 out of 158 trials correctly (87.975%). Epoch Loss: 0.240\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 270\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.174\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 271\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.208\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 272\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.201\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 273\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.163\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 274\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.154\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 275\n",
            "   -- Training Dataset. Got 140 out of 158 trials correctly (88.608%). Epoch Loss: 0.241\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 276\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.197\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 277\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.170\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 278\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.216\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 279\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.168\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 280\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.158\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 281\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.211\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 282\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.216\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 283\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.227\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 284\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.166\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 285\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.203\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 286\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.188\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 287\n",
            "   -- Training Dataset. Got 141 out of 158 trials correctly (89.241%). Epoch Loss: 0.243\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 288\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.121\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 289\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.165\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 290\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.180\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 291\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.224\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 292\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.148\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 293\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.156\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 294\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.124\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 295\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.185\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 296\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.142\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 297\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.175\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 298\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.122\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 299\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.200\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 300\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.192\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 301\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.162\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 302\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.171\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 303\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.236\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 304\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.157\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 305\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.185\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 306\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.123\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 307\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.192\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 308\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.203\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 309\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.127\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 310\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.125\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 311\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.187\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 312\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.172\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 313\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.168\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 314\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.193\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 315\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.179\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 316\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.199\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 317\n",
            "   -- Training Dataset. Got 144 out of 158 trials correctly (91.139%). Epoch Loss: 0.185\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 318\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.146\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 319\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.202\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 320\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.113\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 321\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.177\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 322\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.174\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 323\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.165\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 324\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.154\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 325\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.168\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 326\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.173\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 327\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.123\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 328\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.133\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 329\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.174\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 330\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.147\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 331\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.195\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 332\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.134\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 333\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.114\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 334\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.132\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 335\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.215\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 336\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.134\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 337\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.174\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 338\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.152\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 339\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.190\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 340\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.141\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 341\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.154\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 342\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.141\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 343\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.138\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 344\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.152\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 345\n",
            "   -- Training Dataset. Got 155 out of 158 trials correctly (98.101%). Epoch Loss: 0.102\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 346\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.122\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 347\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.175\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 348\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.134\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 349\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.160\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 350\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.147\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 351\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.123\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 352\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.142\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 353\n",
            "   -- Training Dataset. Got 142 out of 158 trials correctly (89.873%). Epoch Loss: 0.211\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 354\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.110\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 355\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.168\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 356\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.105\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 357\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.195\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 358\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.145\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 359\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.139\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 360\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.208\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 361\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.139\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 362\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.137\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 363\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.149\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 364\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.124\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 365\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.131\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 366\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.104\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 367\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.112\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 368\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.110\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 369\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.119\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 370\n",
            "   -- Training Dataset. Got 156 out of 158 trials correctly (98.734%). Epoch Loss: 0.097\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 371\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.084\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 372\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.140\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 373\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.122\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 374\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.143\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 375\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.127\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 376\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.136\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 377\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.128\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 378\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.096\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 379\n",
            "   -- Training Dataset. Got 157 out of 158 trials correctly (99.367%). Epoch Loss: 0.075\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 380\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.114\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 381\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.108\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 382\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.117\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 383\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.128\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 384\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.153\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 385\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.080\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 386\n",
            "   -- Training Dataset. Got 145 out of 158 trials correctly (91.772%). Epoch Loss: 0.180\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 387\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.114\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 388\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.141\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 389\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.183\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 390\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.092\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 391\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.127\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 392\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.124\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 393\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.118\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 394\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.109\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 395\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.105\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 396\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.114\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 397\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.104\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 398\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.114\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 399\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.116\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 400\n",
            "   -- Training Dataset. Got 143 out of 158 trials correctly (90.506%). Epoch Loss: 0.235\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 401\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.126\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 402\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.114\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 403\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.104\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 404\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.124\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 405\n",
            "   -- Training Dataset. Got 155 out of 158 trials correctly (98.101%). Epoch Loss: 0.072\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 406\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.108\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 407\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.153\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 408\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.160\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 409\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.131\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 410\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.129\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 411\n",
            "   -- Training Dataset. Got 155 out of 158 trials correctly (98.101%). Epoch Loss: 0.078\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 412\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.155\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 413\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.136\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 414\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.133\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 415\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.129\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 416\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.106\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 417\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.131\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 418\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.147\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 419\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.110\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 420\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.125\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 421\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.130\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 422\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.200\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 423\n",
            "   -- Training Dataset. Got 155 out of 158 trials correctly (98.101%). Epoch Loss: 0.097\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 424\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.129\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 425\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.103\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 426\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.133\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 427\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.106\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 428\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.090\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 429\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.126\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 430\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.133\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 431\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.148\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 432\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.123\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 433\n",
            "   -- Training Dataset. Got 151 out of 158 trials correctly (95.570%). Epoch Loss: 0.114\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 434\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.088\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 435\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.147\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 436\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.096\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 437\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.102\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 438\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.100\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 439\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.076\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 440\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.079\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 441\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.131\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 442\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.128\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 443\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.092\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 444\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.113\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 445\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.101\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 446\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.111\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 447\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.088\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 448\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.068\n",
            "   -- Val Dataset. Got 16 out of 22 trials correctly (72.727%)\n",
            "Epoch number 449\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.131\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 450\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.125\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 451\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.140\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 452\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.091\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 453\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.137\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 454\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.138\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 455\n",
            "   -- Training Dataset. Got 146 out of 158 trials correctly (92.405%). Epoch Loss: 0.168\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 456\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.089\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 457\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.110\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 458\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.098\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 459\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.165\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 460\n",
            "   -- Training Dataset. Got 156 out of 158 trials correctly (98.734%). Epoch Loss: 0.073\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 461\n",
            "   -- Training Dataset. Got 155 out of 158 trials correctly (98.101%). Epoch Loss: 0.089\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 462\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.120\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 463\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.124\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 464\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.145\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 465\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.114\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 466\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.140\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 467\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.089\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 468\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.111\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 469\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.108\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 470\n",
            "   -- Training Dataset. Got 156 out of 158 trials correctly (98.734%). Epoch Loss: 0.076\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 471\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.131\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 472\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.140\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 473\n",
            "   -- Training Dataset. Got 155 out of 158 trials correctly (98.101%). Epoch Loss: 0.091\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 474\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.081\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 475\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.124\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 476\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.090\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 477\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.087\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 478\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.139\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 479\n",
            "   -- Training Dataset. Got 147 out of 158 trials correctly (93.038%). Epoch Loss: 0.162\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 480\n",
            "   -- Training Dataset. Got 155 out of 158 trials correctly (98.101%). Epoch Loss: 0.110\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 481\n",
            "   -- Training Dataset. Got 148 out of 158 trials correctly (93.671%). Epoch Loss: 0.149\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 482\n",
            "   -- Training Dataset. Got 155 out of 158 trials correctly (98.101%). Epoch Loss: 0.076\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 483\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.097\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 484\n",
            "   -- Training Dataset. Got 152 out of 158 trials correctly (96.203%). Epoch Loss: 0.101\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 485\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.085\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 486\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.133\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 487\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.107\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 488\n",
            "   -- Training Dataset. Got 150 out of 158 trials correctly (94.937%). Epoch Loss: 0.142\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 489\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.096\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 490\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.133\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 491\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.143\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 492\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.152\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 493\n",
            "   -- Training Dataset. Got 157 out of 158 trials correctly (99.367%). Epoch Loss: 0.081\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 494\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.099\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 495\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.079\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 496\n",
            "   -- Training Dataset. Got 155 out of 158 trials correctly (98.101%). Epoch Loss: 0.099\n",
            "   -- Val Dataset. Got 14 out of 22 trials correctly (63.636%)\n",
            "Epoch number 497\n",
            "   -- Training Dataset. Got 153 out of 158 trials correctly (96.835%). Epoch Loss: 0.087\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 498\n",
            "   -- Training Dataset. Got 155 out of 158 trials correctly (98.101%). Epoch Loss: 0.058\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 499\n",
            "   -- Training Dataset. Got 154 out of 158 trials correctly (97.468%). Epoch Loss: 0.086\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "Epoch number 500\n",
            "   -- Training Dataset. Got 149 out of 158 trials correctly (94.304%). Epoch Loss: 0.136\n",
            "   -- Val Dataset. Got 15 out of 22 trials correctly (68.182%)\n",
            "\n",
            "  -- Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OurNet(\n",
              "  (conv): Conv2d(1, 6, kernel_size=(3, 3), stride=(4, 4))\n",
              "  (pool): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
              "  (batch): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act_f): SELU()\n",
              "  (drop): Dropout(p=0.4, inplace=False)\n",
              "  (lin): Linear(in_features=120, out_features=80, bias=True)\n",
              "  (drop1): Dropout(p=0.3, inplace=False)\n",
              "  (lstm): GRU(80, 60)\n",
              "  (lastlayer): Linear(in_features=60, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('checkpoint.pth.tar')"
      ],
      "metadata": {
        "id": "nO3_SSeSJtqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint['epoch'])\n",
        "print(checkpoint['best accuracy'])\n",
        "print(checkpoint['comments'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg_2vv89Jwrl",
        "outputId": "3215ac1f-4ad7-46c7-cddc-c3301ad9004e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93\n",
            "86.36363636363636\n",
            "sub 33 NORM SGD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = torch.load('best_model.pth.tar')"
      ],
      "metadata": {
        "id": "cU19leNDJzWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_test(model, test_loader):\n",
        "  model.eval()\n",
        "  true_predicted_on_epoch = 0\n",
        "  total = 0\n",
        "  device = set_device()\n",
        "\n",
        "  with torch.no_grad(): #reduce memory usage and speed up the evaluation (no backpropagation che non si fa sul test)\n",
        "    for batch in test_loader:\n",
        "      trial, labels = batch\n",
        "      trial = trial.to(device)\n",
        "      labels = labels.to(device)\n",
        "      total += labels.size(0)\n",
        "\n",
        "      outputs = model(trial.unsqueeze(1).float())\n",
        "\n",
        "      predicted = torch.round(outputs)\n",
        "\n",
        "      true_predicted_on_epoch += (predicted==labels).sum().item()\n",
        "\n",
        "    epoch_accuracy = (true_predicted_on_epoch/total)*100\n",
        "\n",
        "    print(\"   -- Test Dataset. Got %d out of %d trials correctly (%.3f%%)\" %(true_predicted_on_epoch, total, epoch_accuracy))\n",
        "    \n",
        "\n",
        "  return epoch_accuracy"
      ],
      "metadata": {
        "id": "0y7BmpUTR0cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = evaluate_model_test(best_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlKm0DwpKGJF",
        "outputId": "7bda2056-501b-485b-99f4-8e3908548a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   -- Test Dataset. Got 31 out of 44 trials correctly (70.455%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}