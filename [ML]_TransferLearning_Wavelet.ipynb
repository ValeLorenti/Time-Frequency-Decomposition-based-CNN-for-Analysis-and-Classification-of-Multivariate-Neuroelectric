{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCL_kEI5MaBQ"
      },
      "source": [
        "#**Drive mount**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPcE5wbH8VwQ",
        "outputId": "2225a250-11a8-4ac3-957b-657fd8c9e1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFUuzJuIAwe1"
      },
      "source": [
        "#**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEFsFcro8q0_"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms.functional as TF\n",
        "import sklearn.metrics\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torchvision.models as models\n",
        "from torchvision.models.resnet import resnet50\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.io import read_image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from torchvision import datasets\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPfeB-Cf9spV"
      },
      "source": [
        "#**Paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz6WyT7a7qBt"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet'\n",
        "train_path = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/sub50/train'\n",
        "test_path = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/sub50/test'\n",
        "val_path = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/sub50/val'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8xD0fCUJQ0I"
      },
      "source": [
        "#**Carico il dataset in train, path e val trasformandolo direttamente con il trasformatore**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3pFN47gWYuK"
      },
      "outputs": [],
      "source": [
        "def ttv_dataset(train_path, test_path, val_path, train_transforms, test_transforms, val_transforms):\n",
        "\n",
        "    train_dataset = torchvision.datasets.ImageFolder(root = train_path, transform = train_transforms)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(root = test_path, transform = test_transforms)\n",
        "    val_dataset = torchvision.datasets.ImageFolder(root = val_path, transform = val_transforms)\n",
        "\n",
        "    return train_dataset, test_dataset, val_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuErckneJXjs"
      },
      "source": [
        "#**Suddivido in dataloader per velocizzare l'allenamento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMUVMj48rA6Y"
      },
      "outputs": [],
      "source": [
        "def ttv_loader(train_dataset, test_dataset, val_dataset):\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 1, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 1, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-owV0WAaJkiG"
      },
      "source": [
        "#**Calcolo della mean e std per la normalizzazione valido sia per Grayscale che RGB, basta modificare il trasformatore**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lppxmCnuvfb"
      },
      "outputs": [],
      "source": [
        "def mean_and_std(loader):\n",
        "\n",
        "  channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "\n",
        "  for images, _ in loader:\n",
        "    channels_sum += torch.mean(images, dim=[0,2,3])\n",
        "    channels_squared_sum += torch.mean(images**2, dim=[0,2,3])\n",
        "    num_batches += 1\n",
        "\n",
        "  mean = channels_sum/num_batches\n",
        "  std = (channels_squared_sum/num_batches - mean**2)**0.5\n",
        "\n",
        "  return mean, std"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_device():\n",
        "  if torch.cuda.is_available():\n",
        "    dev = \"cuda:0\"\n",
        "  else:\n",
        "    dev = \"cpu\"\n",
        "  return torch.device(dev)"
      ],
      "metadata": {
        "id": "_DJ64WmKgUy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Identity()\n",
        "device = set_device()\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "LzryhvvfhVZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretraining(train_loader, test_loader, val_loader):\n",
        "\n",
        "    batch_t_range = range(0,40)\n",
        "    batch_te_range = range(0,10)\n",
        "    images_total_t = []\n",
        "    images_total_te = []\n",
        "    images_total_v = []\n",
        "    labels_total_t = []\n",
        "    labels_total_te = []\n",
        "    labels_total_v = []\n",
        "\n",
        "\n",
        "    for batch_train in train_loader:\n",
        "      images_t, labels_t = batch_train\n",
        "      images_t = images_t.to(device)\n",
        "      labels_t = labels_t.to(device)\n",
        "      labels_t = labels_t.item()\n",
        "      labels_total_t.append(labels_t)\n",
        "      features_t = model(images_t)\n",
        "      features_t = features_t.cpu().detach().numpy()\n",
        "      images_total_t.append(features_t)\n",
        "\n",
        "    images_total_t = np.squeeze(images_total_t)\n",
        "\n",
        "\n",
        "    for batch_test in test_loader:\n",
        "      images_te, labels_te = batch_test\n",
        "      images_te = images_te.to(device)\n",
        "      labels_te = labels_te.to(device)\n",
        "      labels_te = labels_te.item()\n",
        "      labels_total_te.append(labels_te)\n",
        "      features_te = model(images_te)\n",
        "      features_te = features_te.cpu().detach().numpy()\n",
        "      images_total_te.append(features_te)\n",
        "\n",
        "    images_total_te = np.squeeze(images_total_te)\n",
        "\n",
        "    for batch_val in val_loader:\n",
        "      images_v, labels_v = batch_val\n",
        "      images_v = images_v.to(device)\n",
        "      labels_v = labels_v.to(device)\n",
        "      labels_v = labels_v.item()\n",
        "      labels_total_v.append(labels_v)\n",
        "      features_v = model(images_v)\n",
        "      features_v = features_v.cpu().detach().numpy()\n",
        "      images_total_v.append(features_v)\n",
        "\n",
        "    images_total_v = np.squeeze(images_total_v)\n",
        "\n",
        "    train_data_flatt = images_total_t\n",
        "    test_data_flatt = images_total_te\n",
        "    #test_data_flatt = list(np.concatenate((images_total_te,images_total_v), 0))\n",
        "    train_labels = labels_total_t\n",
        "    test_labels = labels_total_te\n",
        "    #test_labels = list(np.concatenate((labels_total_te,labels_total_v), 0))\n",
        "\n",
        "    return train_data_flatt, test_data_flatt, train_labels, test_labels"
      ],
      "metadata": {
        "id": "KXlXPhtJbMJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ml_classification(train_data_flatt, train_labels, test_data_flatt):\n",
        "    # --SVM--\n",
        "    #Create a svm Classifier\n",
        "    svm_clf = svm.SVC(kernel='rbf') # Linear Kernel\n",
        "\n",
        "    #Train the model using the training sets\n",
        "    svm_clf.fit(train_data_flatt, train_labels)\n",
        "\n",
        "    #Predict the response for test dataset\n",
        "    y_pred_svm = svm_clf.predict(test_data_flatt)\n",
        "\n",
        "    # --RandomForest--\n",
        "\n",
        "    rf_clf = RandomForestClassifier()\n",
        "\n",
        "    rf_clf.fit(train_data_flatt, train_labels)\n",
        "\n",
        "    y_pred_rf = rf_clf.predict(test_data_flatt)\n",
        "\n",
        "     # --XGBoost--\n",
        "\n",
        "    xgb_clf = GradientBoostingClassifier(n_estimators = 100, learning_rate = 1.0, max_depth = 1, random_state = 0)\n",
        "\n",
        "    xgb_clf.fit(train_data_flatt, train_labels)\n",
        "\n",
        "    y_pred_xgb = xgb_clf.predict(test_data_flatt)\n",
        "\n",
        "    print('SVM of sub' + str(sub) + ': ', metrics.accuracy_score(test_labels, y_pred_svm))\n",
        "    print('RandomForest of sub' + str(sub)+ ': ', metrics.accuracy_score(test_labels, y_pred_rf))\n",
        "    print('XGBoost of sub' + str(sub) + ': ', metrics.accuracy_score(test_labels, y_pred_xgb))\n",
        "    print('---------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "NbXNT2v310_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SUBJ_RANGE = range(1,51)\n",
        "\n",
        "for sub in SUBJ_RANGE:\n",
        "  if sub == 1 or sub == 2 or sub == 7 or sub == 8 or sub == 16 or sub == 17 or sub == 36 or sub == 42 or sub == 47:\n",
        "    continue\n",
        "  else:\n",
        "    train_path = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/sub' + str(sub) + '/train'\n",
        "    test_path = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/sub' + str(sub) + '/test'\n",
        "    val_path = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/sub' + str(sub) + '/val'\n",
        "\n",
        "    train_transforms = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])\n",
        "    test_transforms = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])\n",
        "    val_transforms = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])\n",
        "\n",
        "    train_dataset, test_dataset, val_dataset = ttv_dataset(train_path, test_path, val_path, train_transforms, test_transforms, val_transforms)\n",
        "\n",
        "    train_loader, test_loader, val_loader = ttv_loader(train_dataset, test_dataset, val_dataset)\n",
        "    \n",
        "    mean, std = mean_and_std(train_loader)\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "          transforms.Resize((224,224)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
        "    ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "          transforms.Resize((224,224)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))    \n",
        "    ])\n",
        "\n",
        "    val_transforms = transforms.Compose([\n",
        "          transforms.Resize((224,224)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(torch.Tensor(mean), torch.Tensor(std)) \n",
        "    ])\n",
        "\n",
        "\n",
        "    train_dataset, test_dataset, val_dataset = ttv_dataset(train_path, test_path, val_path, train_transforms, test_transforms, val_transforms)\n",
        "\n",
        "    train_loader, test_loader, val_loader = ttv_loader(train_dataset, test_dataset, val_dataset)\n",
        "\n",
        "    train_data_flatt, test_data_flatt, train_labels, test_labels = pretraining(train_loader, test_loader, val_loader)\n",
        "\n",
        "    ml_classification(train_data_flatt, train_labels, test_data_flatt)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi_An2jIW4Bu",
        "outputId": "930ea8d2-e02f-4f0b-9413-64648fa97d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM of sub3:  0.7045454545454546\n",
            "RandomForest of sub3:  0.7045454545454546\n",
            "XGBoost of sub3:  0.5227272727272727\n",
            "---------------------------------------------------------------\n",
            "SVM of sub4:  0.6818181818181818\n",
            "RandomForest of sub4:  0.5909090909090909\n",
            "XGBoost of sub4:  0.6818181818181818\n",
            "---------------------------------------------------------------\n",
            "SVM of sub5:  0.5\n",
            "RandomForest of sub5:  0.8181818181818182\n",
            "XGBoost of sub5:  0.7045454545454546\n",
            "---------------------------------------------------------------\n",
            "SVM of sub6:  0.75\n",
            "RandomForest of sub6:  0.6590909090909091\n",
            "XGBoost of sub6:  0.5909090909090909\n",
            "---------------------------------------------------------------\n",
            "SVM of sub9:  0.6136363636363636\n",
            "RandomForest of sub9:  0.5909090909090909\n",
            "XGBoost of sub9:  0.5\n",
            "---------------------------------------------------------------\n",
            "SVM of sub10:  0.7045454545454546\n",
            "RandomForest of sub10:  0.7727272727272727\n",
            "XGBoost of sub10:  0.7727272727272727\n",
            "---------------------------------------------------------------\n",
            "SVM of sub11:  0.5681818181818182\n",
            "RandomForest of sub11:  0.45454545454545453\n",
            "XGBoost of sub11:  0.5681818181818182\n",
            "---------------------------------------------------------------\n",
            "SVM of sub12:  0.7272727272727273\n",
            "RandomForest of sub12:  0.6363636363636364\n",
            "XGBoost of sub12:  0.5681818181818182\n",
            "---------------------------------------------------------------\n",
            "SVM of sub13:  0.7045454545454546\n",
            "RandomForest of sub13:  0.5909090909090909\n",
            "XGBoost of sub13:  0.5454545454545454\n",
            "---------------------------------------------------------------\n",
            "SVM of sub14:  0.7045454545454546\n",
            "RandomForest of sub14:  0.5909090909090909\n",
            "XGBoost of sub14:  0.5454545454545454\n",
            "---------------------------------------------------------------\n",
            "SVM of sub15:  0.6818181818181818\n",
            "RandomForest of sub15:  0.6363636363636364\n",
            "XGBoost of sub15:  0.6136363636363636\n",
            "---------------------------------------------------------------\n",
            "SVM of sub18:  0.7045454545454546\n",
            "RandomForest of sub18:  0.7272727272727273\n",
            "XGBoost of sub18:  0.7272727272727273\n",
            "---------------------------------------------------------------\n",
            "SVM of sub19:  0.6363636363636364\n",
            "RandomForest of sub19:  0.4772727272727273\n",
            "XGBoost of sub19:  0.4090909090909091\n",
            "---------------------------------------------------------------\n",
            "SVM of sub20:  0.8181818181818182\n",
            "RandomForest of sub20:  0.8181818181818182\n",
            "XGBoost of sub20:  0.7954545454545454\n",
            "---------------------------------------------------------------\n",
            "SVM of sub21:  0.7727272727272727\n",
            "RandomForest of sub21:  0.7954545454545454\n",
            "XGBoost of sub21:  0.5909090909090909\n",
            "---------------------------------------------------------------\n",
            "SVM of sub22:  0.8181818181818182\n",
            "RandomForest of sub22:  0.7727272727272727\n",
            "XGBoost of sub22:  0.5681818181818182\n",
            "---------------------------------------------------------------\n",
            "SVM of sub23:  0.5454545454545454\n",
            "RandomForest of sub23:  0.4772727272727273\n",
            "XGBoost of sub23:  0.5909090909090909\n",
            "---------------------------------------------------------------\n",
            "SVM of sub24:  0.5454545454545454\n",
            "RandomForest of sub24:  0.4772727272727273\n",
            "XGBoost of sub24:  0.5\n",
            "---------------------------------------------------------------\n",
            "SVM of sub25:  0.7045454545454546\n",
            "RandomForest of sub25:  0.7045454545454546\n",
            "XGBoost of sub25:  0.5681818181818182\n",
            "---------------------------------------------------------------\n",
            "SVM of sub26:  0.7727272727272727\n",
            "RandomForest of sub26:  0.7954545454545454\n",
            "XGBoost of sub26:  0.7272727272727273\n",
            "---------------------------------------------------------------\n",
            "SVM of sub27:  0.75\n",
            "RandomForest of sub27:  0.7954545454545454\n",
            "XGBoost of sub27:  0.6590909090909091\n",
            "---------------------------------------------------------------\n",
            "SVM of sub28:  0.6818181818181818\n",
            "RandomForest of sub28:  0.6136363636363636\n",
            "XGBoost of sub28:  0.7045454545454546\n",
            "---------------------------------------------------------------\n",
            "SVM of sub29:  0.5681818181818182\n",
            "RandomForest of sub29:  0.6136363636363636\n",
            "XGBoost of sub29:  0.5909090909090909\n",
            "---------------------------------------------------------------\n",
            "SVM of sub30:  0.6818181818181818\n",
            "RandomForest of sub30:  0.6363636363636364\n",
            "XGBoost of sub30:  0.5909090909090909\n",
            "---------------------------------------------------------------\n",
            "SVM of sub31:  0.6818181818181818\n",
            "RandomForest of sub31:  0.5909090909090909\n",
            "XGBoost of sub31:  0.4772727272727273\n",
            "---------------------------------------------------------------\n",
            "SVM of sub32:  0.7727272727272727\n",
            "RandomForest of sub32:  0.6590909090909091\n",
            "XGBoost of sub32:  0.7727272727272727\n",
            "---------------------------------------------------------------\n",
            "SVM of sub33:  0.45454545454545453\n",
            "RandomForest of sub33:  0.5\n",
            "XGBoost of sub33:  0.5227272727272727\n",
            "---------------------------------------------------------------\n",
            "SVM of sub34:  0.7045454545454546\n",
            "RandomForest of sub34:  0.6590909090909091\n",
            "XGBoost of sub34:  0.7272727272727273\n",
            "---------------------------------------------------------------\n",
            "SVM of sub35:  0.6818181818181818\n",
            "RandomForest of sub35:  0.7045454545454546\n",
            "XGBoost of sub35:  0.5454545454545454\n",
            "---------------------------------------------------------------\n",
            "SVM of sub37:  0.7272727272727273\n",
            "RandomForest of sub37:  0.7272727272727273\n",
            "XGBoost of sub37:  0.6136363636363636\n",
            "---------------------------------------------------------------\n",
            "SVM of sub38:  0.75\n",
            "RandomForest of sub38:  0.5681818181818182\n",
            "XGBoost of sub38:  0.5\n",
            "---------------------------------------------------------------\n",
            "SVM of sub39:  0.6590909090909091\n",
            "RandomForest of sub39:  0.6363636363636364\n",
            "XGBoost of sub39:  0.6363636363636364\n",
            "---------------------------------------------------------------\n",
            "SVM of sub40:  0.6363636363636364\n",
            "RandomForest of sub40:  0.5681818181818182\n",
            "XGBoost of sub40:  0.6818181818181818\n",
            "---------------------------------------------------------------\n",
            "SVM of sub41:  0.6818181818181818\n",
            "RandomForest of sub41:  0.5454545454545454\n",
            "XGBoost of sub41:  0.7954545454545454\n",
            "---------------------------------------------------------------\n",
            "SVM of sub43:  0.5454545454545454\n",
            "RandomForest of sub43:  0.5\n",
            "XGBoost of sub43:  0.6363636363636364\n",
            "---------------------------------------------------------------\n",
            "SVM of sub44:  0.75\n",
            "RandomForest of sub44:  0.7727272727272727\n",
            "XGBoost of sub44:  0.6363636363636364\n",
            "---------------------------------------------------------------\n",
            "SVM of sub45:  0.7727272727272727\n",
            "RandomForest of sub45:  0.5681818181818182\n",
            "XGBoost of sub45:  0.5681818181818182\n",
            "---------------------------------------------------------------\n",
            "SVM of sub46:  0.6363636363636364\n",
            "RandomForest of sub46:  0.4772727272727273\n",
            "XGBoost of sub46:  0.5909090909090909\n",
            "---------------------------------------------------------------\n",
            "SVM of sub48:  0.9090909090909091\n",
            "RandomForest of sub48:  0.9090909090909091\n",
            "XGBoost of sub48:  0.9090909090909091\n",
            "---------------------------------------------------------------\n",
            "SVM of sub49:  0.75\n",
            "RandomForest of sub49:  0.6136363636363636\n",
            "XGBoost of sub49:  0.5681818181818182\n",
            "---------------------------------------------------------------\n",
            "SVM of sub50:  0.8409090909090909\n",
            "RandomForest of sub50:  0.8181818181818182\n",
            "XGBoost of sub50:  0.7954545454545454\n",
            "---------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}