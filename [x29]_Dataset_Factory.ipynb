{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCL_kEI5MaBQ"
      },
      "source": [
        "#**Drive mount**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPcE5wbH8VwQ",
        "outputId": "a1ef866d-53f1-4061-8104-832bba7dbb32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxDvoWQBbSed",
        "outputId": "c3e49534-81b7-49c1-a518-f7bb635987ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ssqueezepy\n",
            "  Downloading ssqueezepy-0.6.3-py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from ssqueezepy) (0.56.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ssqueezepy) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ssqueezepy) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->ssqueezepy) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba->ssqueezepy) (4.13.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->ssqueezepy) (0.39.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->ssqueezepy) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->ssqueezepy) (3.9.0)\n",
            "Installing collected packages: ssqueezepy\n",
            "Successfully installed ssqueezepy-0.6.3\n"
          ]
        }
      ],
      "source": [
        "pip install ssqueezepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8np-oJYrXe2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow\n",
        "import skimage\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision import utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "from ssqueezepy import cwt\n",
        "from ssqueezepy.visuals import plot, imshow\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import glob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maZJA2Yv3oBh"
      },
      "source": [
        "# Checking number of files in train, test, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QNp4fEZ2yww",
        "outputId": "88704909-8e04-4848-ba42-504db59b3aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Non Social files 78\n",
            "Train Social files 79\n",
            "Test Non Social files 22\n",
            "Test Social files 22\n",
            "Val Non Social files 11\n",
            "Val Social files 11\n"
          ]
        }
      ],
      "source": [
        "# folder path\n",
        "num_sub = str(num_sub)\n",
        "   = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/train/nonsocial'\n",
        "train_social = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/train/social'\n",
        "test_nonsocial = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/test/nonsocial'\n",
        "test_social = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/test/social'\n",
        "val_nonsocial = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/val/nonsocial'\n",
        "val_social = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/val/social'\n",
        "\n",
        "num_of_files = 0\n",
        "# Iterate directory\n",
        "for path in os.listdir(train_nonsocial):\n",
        "    # check if current path is a file\n",
        "    if os.path.isfile(os.path.join(train_nonsocial, path)):\n",
        "        num_of_files += 1\n",
        "print('Train Non Social files', num_of_files)\n",
        "\n",
        "num_of_files = 0\n",
        "# Iterate directory\n",
        "for path in os.listdir(train_social):\n",
        "    # check if current path is a file\n",
        "    if os.path.isfile(os.path.join(train_social, path)):\n",
        "        num_of_files += 1\n",
        "print('Train Social files', num_of_files)\n",
        "\n",
        "num_of_files = 0\n",
        "# Iterate directory\n",
        "for path in os.listdir(test_nonsocial):\n",
        "    # check if current path is a file\n",
        "    if os.path.isfile(os.path.join(test_nonsocial, path)):\n",
        "        num_of_files += 1\n",
        "print('Test Non Social files', num_of_files)\n",
        "\n",
        "num_of_files = 0\n",
        "# Iterate directory\n",
        "for path in os.listdir(test_social):\n",
        "    # check if current path is a file\n",
        "    if os.path.isfile(os.path.join(test_social, path)):\n",
        "        num_of_files += 1\n",
        "print('Test Social files', num_of_files)\n",
        "\n",
        "num_of_files = 0\n",
        "# Iterate directory\n",
        "for path in os.listdir(val_nonsocial):\n",
        "    # check if current path is a file\n",
        "    if os.path.isfile(os.path.join(val_nonsocial, path)):\n",
        "        num_of_files += 1\n",
        "print('Val Non Social files', num_of_files)\n",
        "\n",
        "num_of_files = 0\n",
        "# Iterate directory\n",
        "for path in os.listdir(val_social):\n",
        "    # check if current path is a file\n",
        "    if os.path.isfile(os.path.join(val_social, path)):\n",
        "        num_of_files += 1\n",
        "print('Val Social files', num_of_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy7V9J_6AgkD"
      },
      "outputs": [],
      "source": [
        "num_sub = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhLUp9uslm0q",
        "outputId": "9e278a49-ecc0-4e09-f8f1-0730b3bfc5cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minore di 10\n"
          ]
        }
      ],
      "source": [
        "SUBJECTS_FOLDER = '/content/drive/MyDrive/Tirocinio/Datasets/Social memory cuing full dataset/derivatives/EEGPreprocessedDataTableStudy'\n",
        "if num_sub <= 9:\n",
        "  num_sub = str(num_sub)\n",
        "  SINGLE_SUBJECT = os.path.join(SUBJECTS_FOLDER, \"sub-0\" + num_sub + \"/ProcessedData/data_ica.mat\")\n",
        "  print('Minore di 10')\n",
        "\n",
        "else:\n",
        "  num_sub = str(num_sub)\n",
        "  SINGLE_SUBJECT = os.path.join(SUBJECTS_FOLDER, \"sub-\" + num_sub + \"/ProcessedData/data_ica.mat\")\n",
        "  print('Maggiore = di 10')\n",
        "\n",
        "#SUBJECTS = [ name for name in os.listdir(SUBJECTS_FOLDER) if os.path.isdir(os.path.join(SUBJECTS_FOLDER, name)) ]\n",
        "#SUBJECTS.sort()\n",
        "DATA = \"ProcessedData/data_ica.mat\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-tYE8Qrls4H"
      },
      "outputs": [],
      "source": [
        "mat = scipy.io.loadmat(SINGLE_SUBJECT)\n",
        "trial = mat['trial']\n",
        "trialinfo = mat['trialinfo']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP-f0Bx8l37k",
        "outputId": "7dd6d1db-0f3e-410d-ddd8-59dbbb7da832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(125, 29)\n"
          ]
        }
      ],
      "source": [
        "trial = np.transpose(np.squeeze(trial))\n",
        "trials = []\n",
        "labels = []\n",
        "NUM_CHANNELS = 29\n",
        "NUM_TRIAL = 224\n",
        "cueing_fase = range(1250,1750)\n",
        "for i, t in enumerate(trial):\n",
        "  trials.append(t[ :NUM_CHANNELS, cueing_fase])\n",
        "  labels.append(trialinfo[i, 5]-1)  #zero is stick, one is avatar --- the -1 to have labels with 0 or 1 values (in dataset are 1 and 2)\n",
        "\n",
        "trials = list(signal.decimate(np.transpose(trials, [0, 2, 1]), 4, axis = 1)) #downsampling\n",
        "\n",
        "\n",
        "print(np.shape(trials[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4RbLjN7lXlr",
        "outputId": "39c59838-b444-4c1e-9c10-6e0aca69be0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape trials:  (224, 125, 29)\n",
            "Shape trial:  (125, 29)\n",
            "Shape riga trial:  (29,)\n",
            "\n",
            "<class 'list'>\n",
            "<class 'numpy.float64'>\n",
            "[-42.61463921 -31.46198747 -56.00053804  -7.69743213  -3.54184182\n",
            "  -4.4023199   -6.22307626 -19.10046335   6.89144429  -3.04497635\n",
            "  -1.93621139   3.5814017   14.67653137   3.64685107   0.27775719\n",
            "   6.32569456   8.39350586   5.88913852   5.66879864   6.38053792\n",
            "  10.92623594   8.64150507   7.85965478   8.88643233  11.02200811\n",
            "  10.43270732   8.85590631   5.34318613  13.79474039]\n"
          ]
        }
      ],
      "source": [
        "print(f'Shape trials: ', np.shape(trials))\n",
        "print(f'Shape trial: ', np.shape(trials[0]))\n",
        "print(f'Shape riga trial: ', np.shape(trials[0][0]))\n",
        "print()\n",
        "print(type(trials))\n",
        "print(type(trials[0][0][0]))\n",
        "print(trials[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "1ZQr5eALwKtP",
        "outputId": "f06f1a67-7996-4c4c-9372-3514deec8e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub Dispari\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f57192af210>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "if labels[0] == 0 and labels[112] == 1:\n",
        "  print('Sub Dispari')\n",
        "\n",
        "if labels[0] == 1 and labels[112] == 0:\n",
        "  print('Sub Pari')\n",
        "\n",
        "print()\n",
        "print(type(trials[0]))\n",
        "\n",
        "#plt.plot(trials[1][:, 0])\n",
        "plt.plot(trials[0][:, 15:16], color='violet')\n",
        "#plt.plot(trials[0][:, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6K9fPysRt42"
      },
      "source": [
        "# **Trasformazione trial in CWT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYo8umdG8uFZ"
      },
      "outputs": [],
      "source": [
        "trials_cwt = []\n",
        "\n",
        "for idx_trial in range(NUM_TRIAL):\n",
        "  trial = trials[idx_trial]\n",
        "  trial_cwt = []\n",
        "\n",
        "  for idx_col in range(NUM_CHANNELS):\n",
        "    new_col = []\n",
        "    for row in trial:\n",
        "      new_col.append(row[idx_col])\n",
        "\n",
        "    new_col = np.array(new_col)\n",
        "    new_col, scales = cwt(new_col, wavelet = 'morlet')\n",
        "    new_col = abs(new_col)\n",
        "    trial_cwt.append(new_col)\n",
        "\n",
        "  trials_cwt.append(trial_cwt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yceP5q1inULT",
        "outputId": "57f600bc-097d-4b48-a7d0-c8509ce0adce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape di trials_cwt:  (224, 29, 195, 125)\n",
            "Shape di un trial_cwt:  (29, 195, 125)\n",
            "Shape di un trial_cwt trasposto:  (125, 195, 29)\n",
            "Type di un trial_cwt:  <class 'list'>\n",
            "Shape di una colonna di un trial_cwt trasposto:  (195, 29)\n",
            "Shape di una colonna di un trial_cwt:  (195, 125)\n",
            "(195, 125)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f'Shape di trials_cwt: ', np.shape(trials_cwt))\n",
        "#print(f'Trial trasformato in colonna: ', trial_cwt)\n",
        "print(f'Shape di un trial_cwt: ', np.shape(trial_cwt))\n",
        "trial_cwt_trp = np.transpose(trial_cwt)\n",
        "print(f'Shape di un trial_cwt trasposto: ', np.shape(trial_cwt_trp))\n",
        "print(f'Type di un trial_cwt: ', type(trial_cwt))\n",
        "print(f'Shape di una colonna di un trial_cwt trasposto: ', np.shape(trial_cwt_trp[0]))\n",
        "print(f'Shape di una colonna di un trial_cwt: ', np.shape(trial_cwt[0]))\n",
        "print(np.shape(trials_cwt[0][14]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSXLQp2UprGB"
      },
      "outputs": [],
      "source": [
        "cmap = plt.cm.jet\n",
        "plt.imshow(trials_cwt[0][1], aspect='auto', cmap='jet')\n",
        "plt.xlabel('sample')\n",
        "plt.ylabel('scale')\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtoFVtklC72M"
      },
      "outputs": [],
      "source": [
        "def tensor_to_image(tensor):\n",
        "  if type(tensor) == torch.tensor:\n",
        "    pass\n",
        "  else:\n",
        "    tensor = tensor*255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor)>3:\n",
        "        assert tensor.shape[0] == 1\n",
        "        tensor = tensor[0]\n",
        "    return PIL.Image.fromarray(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibzac9LquLOp"
      },
      "source": [
        "**Se sub pari o dispari, salvo le immagini nelle rispettive cartelle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUkLEcJX9ydn"
      },
      "outputs": [],
      "source": [
        "#Se SUB DISPARI\n",
        "if labels[0] == 0 and labels[112] == 1:\n",
        "\n",
        "\n",
        "  NOGRID_TRAIN_RANGE_NONS = range(0,79)\n",
        "  nogrid_path_train_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/train/nonsocial'\n",
        "  grid_path_train_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/train/nonsocial'\n",
        "  NOGRID_TRAIN_RANGE_S = range(112,191)\n",
        "  nogrid_path_train_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/train/social'\n",
        "  grid_path_train_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/train/social'\n",
        "\n",
        "  NOGRID_TEST_RANGE_NONS = range(79,101)\n",
        "  nogrid_path_test_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/test/nonsocial'\n",
        "  grid_path_test_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/test/nonsocial'\n",
        "  NOGRID_TEST_RANGE_S = range(191,213)\n",
        "  nogrid_path_test_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/test/social'\n",
        "  grid_path_test_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/test/social'\n",
        "\n",
        "  NOGRID_VAL_RANGE_NONS = range(101,112)\n",
        "  nogrid_path_val_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/val/nonsocial'\n",
        "  grid_path_val_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/val/nonsocial'\n",
        "  NOGRID_VAL_RANGE_S = range(213,224)\n",
        "  nogrid_path_val_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/val/social'\n",
        "  grid_path_val_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/val/social'\n",
        "\n",
        "  for t in NOGRID_TRAIN_RANGE_NONS:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_train_nons + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_train_nons + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "\n",
        "  for t in NOGRID_TRAIN_RANGE_S:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_train_s + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_train_s + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "  for t in NOGRID_TEST_RANGE_NONS:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_test_nons + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_test_nons + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "  for t in NOGRID_TEST_RANGE_S:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_test_s + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_test_s + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "  for t in NOGRID_VAL_RANGE_NONS:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_val_nons + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_val_nons + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "  for t in NOGRID_VAL_RANGE_S:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_val_s + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_val_s + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "else:\n",
        "  print('Hai sbagliato cella, era pari')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxAjmmEdwlaY"
      },
      "outputs": [],
      "source": [
        "#Se SUB PARI\n",
        "if labels[0] == 1 and labels[112] == 0:\n",
        "\n",
        "\n",
        "  NOGRID_TRAIN_RANGE_S = range(0,79)\n",
        "  nogrid_path_train_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/train/social'\n",
        "  grid_path_train_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/train/social'\n",
        "\n",
        "  NOGRID_TRAIN_RANGE_NONS = range(112,191)\n",
        "  nogrid_path_train_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/train/nonsocial'\n",
        "  grid_path_train_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/train/nonsocial'\n",
        "\n",
        "  NOGRID_TEST_RANGE_S = range(79,101)\n",
        "  nogrid_path_test_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/test/social'\n",
        "  grid_path_test_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/test/social'\n",
        "\n",
        "  NOGRID_TEST_RANGE_NONS = range(191,213)\n",
        "  nogrid_path_test_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/test/nonsocial'\n",
        "  grid_path_test_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/test/nonsocial'\n",
        "\n",
        "  NOGRID_VAL_RANGE_S = range(101,112)\n",
        "  nogrid_path_val_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/val/social'\n",
        "  grid_path_val_s = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/val/social'\n",
        "\n",
        "  NOGRID_VAL_RANGE_NONS = range(213,224)\n",
        "  nogrid_path_val_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid/sub' + num_sub + '/val/nonsocial'\n",
        "  grid_path_val_nons = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/Grid/sub' + num_sub + '/val/nonsocial'\n",
        "\n",
        "  for t in NOGRID_TRAIN_RANGE_S:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_train_s + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_train_s + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "  for t in NOGRID_TRAIN_RANGE_NONS:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_train_nons + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_train_nons + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "\n",
        "  for t in NOGRID_TEST_RANGE_S:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_test_s + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_test_s + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "  for t in NOGRID_TEST_RANGE_NONS:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_test_nons + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_test_nons + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "\n",
        "  for t in NOGRID_VAL_RANGE_S:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_val_s + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_val_s + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "  for t in NOGRID_VAL_RANGE_NONS:\n",
        "    images = []\n",
        "    for r in range(NUM_CHANNELS):\n",
        "      trials_cwt[t][r] = torch.from_numpy(trials_cwt[t][r])\n",
        "      image = tensor_to_image(trials_cwt[t][r])\n",
        "      image = image.resize((224, 224))\n",
        "      image = nogrid_path_val_nons + '/trial_' + str(t) + '_num channel_' + str(r) + '.png'\n",
        "      plt.imsave(image, trials_cwt[t][r], cmap=cmap)\n",
        "\n",
        "      img = torch.tensor(plt.imread(image))\n",
        "      img = img.permute(2, 0, 1)\n",
        "      images.append(img)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow = 6)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    #plt.imshow(np.transpose(grid, (1,2,0)), aspect='auto', cmap= 'jet')\n",
        "    plt.imsave(grid_path_val_nons + '/grid_trial' + str(t) + '.png', np.transpose(grid, (1,2,0)).numpy(), cmap= 'jet')\n",
        "\n",
        "else:\n",
        "  print('Hai sbagliato cella, era dispari')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04Fmx26auG6F"
      },
      "source": [
        "*Creazione Cartelle per Dataset*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqqX5rNScSM4"
      },
      "outputs": [],
      "source": [
        "SUBJ_RANGE = range(1,51)\n",
        "\n",
        "grid_path = '/content/drive/MyDrive/Tirocinio/Datasets/SocialMemoryImgs/Wavelet_Abs_Plt_Jet/NoGrid'\n",
        "train_test_val = ['train', 'test', 'val']\n",
        "nonsocial_social = ['nonsocial','social']\n",
        "for sub in SUBJ_RANGE:\n",
        "  if sub == 1 or sub == 2 or sub == 7 or sub == 8 or sub == 16 or sub == 17 or sub == 36 or sub == 42 or sub == 47:\n",
        "    continue\n",
        "  else:\n",
        "    os.mkdir(grid_path + '/sub' + str(sub))\n",
        "    sub_path = grid_path + '/sub' + str(sub)\n",
        "    for ttv in train_test_val:\n",
        "      path = os.path.join(sub_path, ttv)\n",
        "      os.mkdir(path)\n",
        "      for nss in nonsocial_social:\n",
        "        path_s = os.path.join(path, nss)\n",
        "        os.mkdir(path_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FP5bYzJzDIOG"
      },
      "outputs": [],
      "source": [
        "m = [[1,2,3],\n",
        "     [4,5,6],\n",
        "     [7,8,9]]\n",
        "\n",
        "m_trasp = []\n",
        "\n",
        "print(np.shape(m))\n",
        "num_col = range(3)\n",
        "\n",
        "for c in range(num_col):\n",
        "  new_col  = []\n",
        "  for r in m:\n",
        "    new_col.append(r[c])\n",
        "  new_col = np.transpose(new_col)\n",
        "  m_trasp.append(new_col)\n",
        "\n",
        "\n",
        "print(f'M:  ', m)\n",
        "print(f'M Trasp:  ', m_trasp)\n",
        "\n",
        "print(m[0])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}